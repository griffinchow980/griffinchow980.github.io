---
title: "LLM"
date: 2024-11-12
---

# LLM基础概念

{{< details "**什么是LLM（大语言模型）？**" "大模型" >}}

LLM（Large Language Model，大语言模型）是基于Transformer架构、通过大规模文本数据训练的深度学习模型，能够理解和生成人类语言。

**核心特征**：

- **规模庞大**：参数量通常在数十亿到数千亿级别
  - GPT-3：175B参数
  - GPT-4：据估计超过1T参数
  - Claude 3：参数量未公开，但能力超越GPT-3.5

- **预训练 + 微调**：
  - 预训练：在大规模无标注文本上学习语言规律
  - 微调：针对特定任务进行优化（如对话、编程、分析等）

- **涌现能力**（Emergent Abilities）：
  - 当模型规模达到一定程度，会自然涌现出一些未被明确训练的能力
  - 如：逻辑推理、代码生成、数学计算、多语言理解等

**主要能力**：

1. **自然语言理解**：理解文本含义、上下文、情感等
2. **文本生成**：创作文章、对话、代码、翻译等
3. **知识问答**：回答各领域问题
4. **推理能力**：逻辑推理、数学推理、因果推理
5. **任务适应**：通过Prompt快速适应新任务

**常见的LLM对比**：

| 厂商 | 模型系列 | 主要特点 | 典型应用 |
|------|---------|---------|---------|
| **OpenAI** | GPT-3.5、GPT-4、GPT-4 Turbo | 综合能力强、API稳定 | ChatGPT、代码辅助、内容生成 |
| **Anthropic** | Claude 3 (Haiku/Sonnet/Opus) | 安全性高、上下文长、推理强 | 复杂任务、长文档分析 |
| **Google** | Gemini、PaLM 2 | 多模态、搜索整合 | 搜索增强、图文理解 |
| **Meta** | Llama 2、Llama 3 | 开源、可本地部署 | 私有化部署、研究 |
| **国内** | 文心一言、通义千问、智谱GLM、Kimi | 中文优化、长文本 | 中文场景、知识问答 |

**应用场景**：

- 智能客服、内容创作、代码辅助
- 数据分析、知识问答、教育辅导
- 文本摘要、翻译、信息抽取

{{< /details >}}

{{< details "**什么是Prompt Engineering（提示词工程）？**" "提示词" >}}

Prompt Engineering是设计和优化输入提示词（Prompt）以获得更好LLM输出的技术和方法。

**为什么需要Prompt Engineering**：

LLM的输出质量高度依赖于输入的Prompt质量：
- 不清晰的Prompt → 模糊、不准确的回答
- 精心设计的Prompt → 精准、高质量的输出

**Prompt的基本要素**：

{{< tabs "角色设定,任务描述,背景信息,输出格式" >}}

**Role（角色）**

明确AI的角色定位：

```
你是一位资深的数据分析师，擅长用户行为分析和AB测试...
```

作用：
- 设定回答的视角和专业度
- 约束回答的范围和深度

|||

**Task（任务）**

清晰描述要完成的任务：

```
请分析这组用户行为数据，找出影响留存率的关键因素...
```

要点：
- 具体、明确
- 可执行、可衡量
- 一次只做一个主要任务

|||

**Context（背景）**

提供必要的上下文信息：

```
背景：某社交APP在10月上线新版本后，次日留存率从40%降到28%
数据：附带用户行为数据CSV文件
目标：找到留存下降的原因
```

作用：
- 帮助模型更好理解问题
- 提供决策依据

|||

**Format（格式）**

指定输出格式：

```
请按照以下格式输出：
1. 数据概览（3-5个核心指标）
2. 问题分析（分点说明）
3. 改进建议（具体可行的方案）
4. 预期效果（量化预估）
```

作用：
- 结构化输出，易于理解
- 确保包含关键信息

{{< /tabs >}}

**Prompt优化技巧**：

1. **Few-Shot Learning（少样本学习）**

提供示例引导模型：

```
示例1：
输入：[数据]
输出：[期望的分析]

示例2：
输入：[数据]
输出：[期望的分析]

现在请分析：[实际数据]
```

2. **Chain of Thought（思维链）**

引导模型一步步思考：

```
让我们一步步分析：
1. 首先，计算各环节的转化率
2. 然后，识别转化率异常的环节
3. 接下来，分析可能的原因
4. 最后，提出优化建议
```

3. **明确约束条件**

```
要求：
- 答案不超过500字
- 用数据支撑结论
- 提供3个具体可行的方案
- 不要使用专业术语，用通俗语言解释
```

**常见问题与优化**：

{{< admonition type="tip" title="Prompt优化前后对比" collapse="false" >}}

**❌ 不好的Prompt**：
"分析这个数据"

问题：过于模糊，缺少目标和约束

**✅ 优化后的Prompt**：
```
你是一位数据分析专家。请分析以下用户购买数据，完成以下任务：

1. 计算整体转化率和各环节转化率
2. 找出转化率最低的环节（流失点）
3. 分析该环节流失的可能原因
4. 提出3个具体的优化建议

要求：
- 用数据支撑结论
- 建议需要可执行、可衡量
- 输出格式为Markdown表格
```

{{< /admonition >}}

**进阶技巧**：

- **Self-Consistency**：多次生成，选择最一致的答案
- **ReAct**：推理（Reasoning）+ 行动（Acting）交替进行
- **Tree of Thoughts**：探索多个思维路径，选择最优解

{{< /details >}}

{{< details "**什么是RAG（检索增强生成）？**" "AI" >}}

RAG（Retrieval-Augmented Generation，检索增强生成）是一种结合信息检索和文本生成的技术，通过从外部知识库检索相关信息来增强LLM的生成能力。

**为什么需要RAG**：

LLM面临的局限：
- **知识截止日期**：训练数据有时间限制，无法获取最新信息
- **幻觉问题**：可能编造不存在的信息
- **领域知识不足**：对特定领域（如企业内部数据）了解有限
- **无法引用来源**：难以验证信息的准确性

RAG的优势：
- 提供最新信息和特定领域知识
- 减少幻觉，提高准确性
- 可追溯信息来源
- 无需重新训练模型

**RAG的基本流程**：

```
用户问题
    ↓
1. 查询理解（问题改写、关键词提取）
    ↓
2. 检索相关文档（向量检索、关键词检索）
    ↓
3. 文档重排序（选择最相关的top-k）
    ↓
4. 构建Prompt（问题 + 检索到的上下文）
    ↓
5. LLM生成答案
    ↓
6. 后处理（格式化、引用来源）
    ↓
答案输出
```

**RAG的核心组件**：

{{< tabs "向量数据库,Embedding模型,检索策略,生成策略" >}}

**向量数据库（Vector DB）**

存储文档的向量表示：

常用向量数据库：
- Pinecone（云服务）
- Milvus（开源）
- Weaviate（开源）
- Chroma（轻量级）
- FAISS（Facebook开源）

作用：
- 高效存储和检索向量
- 支持相似度搜索
- 支持大规模数据

|||

**Embedding模型**

将文本转换为向量：

常用模型：
- OpenAI Embedding（text-embedding-3-small/large）
- BGE系列（BAAI/bge-large-zh）
- M3E（moka-ai/m3e-base）

作用：
- 将文本映射到高维向量空间
- 语义相似的文本距离近

|||

**检索策略**

如何找到相关文档：

1. **稠密检索**（Dense Retrieval）
   - 使用向量相似度（余弦相似度）
   - 捕捉语义相似性
   - 效果好但计算成本高

2. **稀疏检索**（Sparse Retrieval）
   - BM25等关键词匹配
   - 精确匹配关键词
   - 速度快但语义理解弱

3. **混合检索**（Hybrid）
   - 结合稠密和稀疏检索
   - 取长补短

|||

**生成策略**

如何利用检索结果：

Prompt模板：
```
基于以下上下文回答问题：

上下文1: [检索到的文档1]
上下文2: [检索到的文档2]
上下文3: [检索到的文档3]

问题：{用户问题}

要求：
- 只根据上下文回答，不要编造信息
- 如果上下文不包含答案，请明确说明
- 请引用具体的上下文来源
```

{{< /tabs >}}

**RAG的优化技巧**：

1. **文档分块（Chunking）**
   - 合理的chunk大小（通常512-1024 tokens）
   - 保持语义完整性
   - 添加重叠（overlap）避免信息割裂

2. **查询优化**
   - 问题改写：将复杂问题拆解
   - 关键词提取：提取核心概念
   - 多查询：从不同角度检索

3. **重排序（Reranking）**
   - 使用专门的重排序模型
   - 根据相关性对检索结果重新排序
   - 提升top-k结果的质量

4. **混合检索**
   - 结合向量检索和关键词检索
   - 利用各自优势

**RAG的应用场景**：

- **企业知识库问答**：基于内部文档回答员工问题
- **客户服务**：基于产品文档和FAQ回答用户问题
- **法律/医疗咨询**：基于专业文献提供建议
- **代码助手**：基于代码库回答编程问题

{{< admonition type="warning" title="RAG的挑战" collapse="false" >}}

1. **检索质量**：如果检索不到相关文档，生成质量会下降
2. **上下文长度限制**：LLM的上下文窗口有限，不能塞入太多文档
3. **延迟问题**：检索 + 生成增加了响应时间
4. **成本**：需要维护向量数据库和Embedding服务

{{< /admonition >}}

{{< /details >}}

{{< details "**什么是AI Agent（智能体）？**" "AI-Agent" >}}

AI Agent是能够感知环境、自主决策并执行行动以达成目标的智能系统。相比传统LLM的单次问答，Agent能够进行多步推理、使用工具、并迭代优化以完成复杂任务。

**Agent的核心能力**：

1. **感知（Perception）**：理解用户意图和环境状态
2. **规划（Planning）**：制定达成目标的行动计划
3. **执行（Execution）**：调用工具和API执行具体操作
4. **反思（Reflection）**：评估结果，调整策略
5. **记忆（Memory）**：存储历史信息，支持长期交互

**Agent的基本架构**：

```
用户输入
    ↓
┌─────────────────────┐
│   LLM核心引擎       │
│  (推理与决策)       │
└─────────────────────┘
    ↓         ↓
计划制定    工具调用
    ↓         ↓
┌─────────────────────┐
│  工具箱 (Tools)     │
│  - 搜索引擎         │
│  - 计算器          │
│  - 数据库查询      │
│  - API调用         │
│  - 文件操作        │
└─────────────────────┘
    ↓
┌─────────────────────┐
│  记忆系统           │
│  - 短期记忆（对话） │
│  - 长期记忆（知识） │
└─────────────────────┘
    ↓
结果输出
```

**Agent vs LLM对话**：

{{< tabs "传统LLM,AI Agent" >}}

**传统LLM对话**

特点：
- 单轮问答
- 只能基于训练数据回答
- 无法执行实际操作
- 无法获取实时信息

示例：
```
用户：帮我查一下明天深圳的天气
LLM：抱歉，我无法获取实时天气信息，
     我的训练数据截止到2023年...
```

|||

**AI Agent**

特点：
- 多步推理和规划
- 可以调用工具
- 可以执行实际操作
- 可以获取实时信息

示例：
```
用户：帮我查一下明天深圳的天气

Agent思考过程：
1. 理解意图：查询天气
2. 制定计划：调用天气API
3. 执行：search_weather("深圳", "明天")
4. 返回结果：
   "明天深圳天气：晴，22-28°C，
    建议穿着轻便..."
```

{{< /tabs >}}

**常见的Agent框架**：

1. **ReAct（Reasoning + Acting）**

交替进行推理和行动：

```
Thought: 我需要先查询用户的订单信息
Action: query_database(user_id=123)
Observation: 用户有3个订单，最近一个是...

Thought: 基于订单信息，我可以回答用户的问题了
Action: generate_response(...)
```

2. **AutoGPT类**

自主规划和执行多步任务：
- 分解任务为子任务
- 逐步执行并验证
- 自我纠错和优化

3. **Multi-Agent系统**

多个Agent协作完成复杂任务：
- 专家Agent：各司其职（如数据分析Agent、写作Agent）
- 管理Agent：协调和分配任务
- 评估Agent：质量控制

**Agent的应用场景**：

- **数据分析助手**：自动获取数据、分析、生成报告
- **客户服务**：查询订单、处理退款、解答问题
- **代码助手**：理解需求、编写代码、调试、测试
- **研究助手**：文献搜索、信息提取、报告生成
- **个人助理**：日程管理、邮件处理、信息整理

**Agent的工具（Tools）**：

{{< admonition type="tip" title="常见工具类型" collapse="false" >}}

1. **搜索工具**：
   - 网页搜索（Google、Bing）
   - 知识库搜索
   - 文档搜索

2. **计算工具**：
   - 计算器
   - Python解释器
   - 数据分析工具

3. **数据工具**：
   - SQL查询
   - API调用
   - 数据库操作

4. **文件工具**：
   - 读写文件
   - 文档解析（PDF、Word）
   - 图片处理

5. **通信工具**：
   - 发送邮件
   - 消息通知
   - API接口调用

{{< /admonition >}}

**Agent的挑战**：

1. **可靠性**：多步推理可能出错，需要错误处理机制
2. **成本**：多次调用LLM，成本较高
3. **安全性**：需要限制Agent的权限，防止误操作
4. **可控性**：确保Agent按预期行为，不"失控"

{{< /details >}}

{{< details "**什么是Fine-tuning（微调）？**" "大模型" >}}

Fine-tuning是在预训练模型的基础上，使用特定领域的数据继续训练，使模型适应特定任务或风格的过程。

**为什么需要Fine-tuning**：

- **提升特定任务表现**：在垂直领域（如医疗、法律）效果更好
- **定制输出风格**：符合企业的语气、格式要求
- **减少Prompt长度**：通过训练固化行为，减少每次推理的Prompt
- **提高效率**：小模型微调后可以达到大模型的效果

**Fine-tuning的类型**：

{{< tabs "全量微调,PEFT,LoRA" >}}

**Full Fine-tuning（全量微调）**

更新模型的所有参数：

特点：
- 效果最好
- 计算成本高（需要大量GPU）
- 需要大量训练数据（通常数千到数万条）

适用场景：
- 有充足资源和数据
- 对效果要求极高
- 领域差异很大

|||

**PEFT（参数高效微调）**

只更新部分参数：

方法：
- Adapter：在模型中插入小模块
- Prefix-tuning：只训练前缀向量
- Prompt-tuning：优化连续的Prompt

优点：
- 参数量小，训练快
- 多任务切换方便
- 降低成本

|||

**LoRA（低秩适应）**

最流行的PEFT方法：

原理：
- 冻结原模型参数
- 添加低秩矩阵进行训练
- 训练参数量仅为原模型的0.1-1%

优点：
- 显著降低训练成本
- 可以并行训练多个LoRA
- 推理时几乎无额外开销

{{< /tabs >}}

**Fine-tuning的流程**：

1. **数据准备**
   - 收集特定领域的高质量数据
   - 格式化为训练格式（通常是问答对）
   - 数据清洗和质量控制

2. **选择基座模型**
   - 根据任务选择合适的预训练模型
   - 考虑模型大小、语言、许可证

3. **训练**
   - 设置超参数（学习率、batch size等）
   - 监控训练过程，防止过拟合
   - 在验证集上评估效果

4. **评估与迭代**
   - 在测试集上评估效果
   - 根据效果调整数据和参数
   - 迭代优化

**Fine-tuning vs Prompt Engineering vs RAG**：

| 维度 | Prompt Engineering | RAG | Fine-tuning |
|------|-------------------|-----|-------------|
| 成本 | 低 | 中 | 高 |
| 效果 | 一般 | 好 | 最好 |
| 灵活性 | 高 | 中 | 低 |
| 数据需求 | 少 | 中 | 多 |
| 适用场景 | 通用任务 | 知识问答 | 专业领域 |

**选择建议**：

- **简单任务** → Prompt Engineering
- **需要最新/专业知识** → RAG
- **特定领域深度定制** → Fine-tuning
- **综合方案** → RAG + Fine-tuning

{{< /details >}}

{{< details "**什么是MCP（模型上下文协议）？**" "AI" >}}

MCP（Model Context Protocol）是Anthropic提出的一个开放协议标准，用于在AI应用和数据源之间建立标准化的连接方式，使AI模型能够安全、高效地访问外部数据和工具。

**MCP解决的问题**：

传统AI应用接入数据源的痛点：
- **碎片化**：每个数据源需要单独集成
- **重复开发**：不同AI应用都要重新实现相同的集成
- **维护困难**：数据源变化需要更新所有集成
- **安全问题**：没有统一的权限和安全标准

**MCP的核心理念**：

就像USB协议统一了设备连接，MCP旨在统一AI与数据源的连接：

```
传统方式：
AI App 1 ──→ 数据源A的专有接口
AI App 1 ──→ 数据源B的专有接口
AI App 2 ──→ 数据源A的专有接口（重复开发）
AI App 2 ──→ 数据源B的专有接口（重复开发）

MCP方式：
AI App 1 ──→ MCP协议 ←── 数据源A的MCP Server
AI App 2 ──→ MCP协议 ←── 数据源B的MCP Server
```

**MCP的架构**：

{{< tabs "MCP Host,MCP Server,MCP Client" >}}

**MCP Host（宿主）**

运行AI应用的环境：

- Claude Desktop
- IDE（如Cursor、VS Code）
- 自定义AI应用

职责：
- 管理与多个MCP Server的连接
- 协调资源和权限
- 提供用户界面

|||

**MCP Server（服务器）**

数据源的标准化接口：

示例：
- 文件系统MCP Server
- 数据库MCP Server
- Git MCP Server
- Web搜索MCP Server

职责：
- 暴露数据和工具
- 实现MCP协议
- 处理权限和安全

|||

**MCP Client（客户端）**

AI应用中的连接组件：

职责：
- 发现和连接MCP Server
- 发送请求和接收响应
- 管理会话状态

{{< /tabs >}}

**MCP的核心概念**：

1. **Resources（资源）**
   - 数据源暴露的数据
   - 如：文件、数据库记录、API端点

2. **Tools（工具）**
   - AI可以调用的操作
   - 如：搜索、写入文件、执行查询

3. **Prompts（提示模板）**
   - 预定义的提示词模板
   - 帮助用户快速使用常见功能

**MCP的优势**：

- **标准化**：统一的接口，降低集成复杂度
- **复用性**：一次开发，多处使用
- **安全性**：统一的权限和安全控制
- **可扩展**：轻松添加新的数据源和工具

**MCP的应用场景**：

- **企业知识库集成**：AI访问公司文档、数据库
- **开发工具集成**：AI访问代码仓库、终端、文件系统
- **数据分析**：AI访问数据仓库、BI工具
- **自动化工作流**：AI调用各种第三方服务

**实际例子**：

在Cursor中使用MCP访问文件系统：

```
用户：帮我分析这个项目的代码结构

AI（通过MCP）：
1. 调用filesystem MCP Server列出文件
2. 读取关键文件内容
3. 分析并总结代码结构
4. 生成结构图和说明
```

{{< admonition type="note" title="MCP的发展状态" collapse="false" >}}

MCP是2024年提出的新协议，目前还在早期阶段：

- Anthropic的Claude Desktop已支持
- 社区在积极开发各种MCP Server
- 未来可能成为AI应用的标准协议

类比：MCP希望成为AI领域的"USB协议"或"HTTP协议"

{{< /admonition >}}

{{< /details >}}

# 进阶概念

{{< details "**什么是Token？如何计算Token数量？**" "大模型" >}}

Token是LLM处理文本的基本单位，可以理解为文本的"原子"。

**Token的本质**：

- 不是完整的单词，也不是单个字符
- 而是常见的字符序列（subword）
- 通过分词算法（如BPE）将文本切分

**Token的示例**：

中文：
```
"数据分析" → ["数据", "分析"] （2个token）
"我爱编程" → ["我", "爱", "编", "程"] （4个token）
```

英文：
```
"Hello world" → ["Hello", " world"] （2个token）
"ChatGPT" → ["Chat", "GPT"] （2个token）
```

**为什么不是按字符或单词**：

- **按字符**：太细粒度，序列太长，训练和推理效率低
- **按单词**：词表太大，无法处理未见过的词
- **Token（subword）**：平衡了效率和灵活性

**Token数量估算**：

粗略估算：
- **中文**：1个汉字 ≈ 1-2个token
- **英文**：1个单词 ≈ 1-2个token
- **代码**：因缩进和符号，通常比自然语言多

精确计算：
- 使用OpenAI的tiktoken库
- 或各模型提供的tokenizer

**Token的重要性**：

1. **成本计算**：
   - API按token计费
   - 输入token + 输出token = 总成本

2. **长度限制**：
   - 每个模型有最大token限制
   - GPT-3.5: 4K/16K
   - GPT-4: 8K/32K/128K
   - Claude 3: 200K

3. **性能影响**：
   - Token越多，推理越慢
   - Token越多，成本越高

{{< /details >}}

{{< details "**什么是Temperature和Top-p采样？**" "大模型" >}}

Temperature和Top-p是控制LLM生成文本随机性和多样性的两个重要参数。

**Temperature（温度）**：

控制输出的"创造性"vs"确定性"：

- **Temperature = 0**：完全确定，总是选择概率最高的token
  - 适合：事实问答、代码生成、数据分析
  - 特点：输出稳定、可预测

- **Temperature = 0.7**（默认）：平衡创造性和稳定性
  - 适合：对话、内容创作

- **Temperature = 1.0-2.0**：高创造性，输出更随机
  - 适合：创意写作、头脑风暴
  - 特点：输出多样、有时不够精确

工作原理：
```
调整概率分布的"陡峭程度"
Temperature越低 → 分布越陡峭 → 更确定
Temperature越高 → 分布越平缓 → 更随机
```

**Top-p（核采样）**：

也称为Nucleus Sampling，控制候选token的范围：

- **Top-p = 0.1**：只考虑累计概率前10%的token
  - 输出更集中、更保守

- **Top-p = 0.9**（常用）：考虑累计概率前90%的token
  - 平衡多样性和质量

- **Top-p = 1.0**：考虑所有token
  - 最大多样性

**Temperature vs Top-p**：

{{< tabs "Temperature,Top-p,组合使用" >}}

**Temperature单独使用**

适合场景：
- 需要精确控制随机程度
- 简单场景

设置建议：
- 事实性任务：0-0.3
- 对话：0.7-0.9
- 创作：1.0-1.5

|||

**Top-p单独使用**

适合场景：
- 动态调整候选范围
- 避免低质量输出

设置建议：
- 保守：0.5-0.7
- 平衡：0.9
- 开放：0.95-1.0

|||

**组合使用**

最佳实践：
- Temperature=0.7, Top-p=0.9（通用设置）
- Temperature=0, Top-p=1.0（确定性任务）
- Temperature=1.0, Top-p=0.95（创造性任务）

注意：
- 两个参数都设置很低可能过于保守
- 两个参数都设置很高可能输出质量低

{{< /tabs >}}

{{< admonition type="tip" title="参数调优建议" collapse="false" >}}

不同任务的推荐设置：

**数据分析**：
- Temperature: 0-0.3
- Top-p: 0.9
- 原因：需要精确、客观的分析

**代码生成**：
- Temperature: 0-0.2
- Top-p: 0.9
- 原因：代码需要准确性

**创意写作**：
- Temperature: 0.8-1.2
- Top-p: 0.95
- 原因：需要多样性和创造力

**客户服务**：
- Temperature: 0.5-0.7
- Top-p: 0.9
- 原因：平衡准确性和自然度

{{< /admonition >}}

{{< /details >}}

{{< details "**什么是Embedding（向量嵌入）？**" "大模型" >}}

Embedding是将文本、图片等非结构化数据转换为固定维度向量的技术，使计算机能够"理解"和比较语义相似度。

**为什么需要Embedding**：

计算机无法直接理解文本含义：
- "猫"和"狗"对计算机只是不同的字符串
- 无法判断"机器学习"和"人工智能"是相关概念

Embedding将文本映射到向量空间：
- 语义相似的文本在向量空间中距离近
- 可以进行数学运算和相似度计算

**Embedding的表示**：

示例（简化为3维）：
```
"数据分析" → [0.8, 0.3, 0.1]
"数据科学" → [0.7, 0.4, 0.2]  # 距离近，语义相似
"篮球比赛" → [0.1, 0.2, 0.9]  # 距离远，语义不相关
```

实际模型：
- OpenAI Embedding: 1536维
- BGE-large: 1024维
- M3E: 768维

**相似度计算**：

常用方法：余弦相似度

```
similarity = cos(θ) = (A·B) / (||A|| × ||B||)

值范围：-1到1
- 1：完全相同
- 0：无关
- -1：完全相反
```

**Embedding的应用**：

1. **语义搜索**
   - 将查询和文档都转为向量
   - 计算相似度，返回最相关文档

2. **推荐系统**
   - 将用户和物品转为向量
   - 推荐相似物品

3. **聚类分析**
   - 将文本转为向量
   - 使用K-Means等算法聚类

4. **RAG系统**
   - 核心组件
   - 用于文档检索

**常用Embedding模型**：

{{< tabs "OpenAI,开源中文,开源多语言" >}}

**OpenAI Embedding**

模型：
- text-embedding-3-small（1536维）
- text-embedding-3-large（3072维）

优点：
- 效果好
- API简单

缺点：
- 需要付费
- 数据上传到OpenAI

|||

**开源中文模型**

推荐：
- BGE系列（BAAI/bge-large-zh）
- M3E（moka-ai/m3e-base）
- Text2vec

优点：
- 免费
- 可本地部署
- 中文效果好

|||

**开源多语言模型**

推荐：
- sentence-transformers/all-MiniLM-L6-v2
- sentence-transformers/paraphrase-multilingual-mpnet-base-v2

优点：
- 支持多语言
- 社区活跃

{{< /tabs >}}

**Embedding的实践建议**：

1. **选择合适的模型**
   - 根据语言、领域、性能要求选择
   - 中文任务优先考虑专门的中文模型

2. **文档切分**
   - Embedding前要合理切分文档
   - 保持语义完整性
   - 通常512-1024 tokens per chunk

3. **缓存Embedding**
   - Embedding计算耗时
   - 对不变的文本缓存结果

4. **混合检索**
   - Embedding检索（语义）+ 关键词检索（精确）
   - 效果更好

{{< /details >}}

