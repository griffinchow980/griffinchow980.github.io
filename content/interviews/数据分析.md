---
title: "数据分析"
date: 2025-03-16T10:00:00+08:00
draft: false
---
# 数据分析基础
{{< details "数据分析思维是什么？怎么去验证？">}}

数据分析思维是**使用数据分析技能解决问题**

通过三个问题验证是否具备数据分析思维：
- 到底要怎么分析问题？
- 到底分析出什么结论？
- 这个结论有什么用？
{{< /details >}}


# 业务指标与模型

# A/B测试

## 是什么

### 请描述一下什么是A/B-test？
{{< details "请描述一下什么是A/B-test？" "A/B测试">}}
定义类回答技巧：专业定义 + 场景结合

**统计学定义**：
- A/B测试是一种基于统计学的实验方法
- 通过设置对照组和实验组对变量进行试验
- 然后通过假设检验对不同组的结果进行检验
- 判断变量是否对最终结果造成显著影响
- 从而帮助选取最合理的方法

<br/>

**业务场景应用**: 
- AB测试是为同一目标制定不同页面版本
- 将用户流量分成对应组别
- 在同一时间维度让不同组用户随机访问这些版本
- 通过埋点设计收集各群组的用户体验和业务数据
- 分析评估出最优版本并正式采用
{{< /details >}}

### A/B测试的核心原理是什么？

{{< details "A/B测试的核心原理是什么？" "A/B测试">}}
**A/B测试本质就是一个基于统计的假设检验过程**
1. 通过**随机合理分流**，设置对照组和实验组
2. 通过**控制变量法**，观察两组用户在一段时间内的表现
3. 通过**假设检验**，分析结果是否有显著差异从而判断改动是否有效可执行

<br/>

其他理论：
- **中心极限定理**：样本量足够大时，变量均值的抽样分布都近似于正态分布
- **小概率事件**：小概率事件在一次实验中基本上不会发生
- **反证法**：假设检验的机制是保护原假设，所以把要拒绝的假设放在原假设的位置，如果原假设成立的条件下，小概率事件还是发生了，那么就应该推翻原假设
- **P值**：P值越小，拒绝原假设的理由就越充分

{{< /details >}}

### A/B测试有哪些应用场景？

{{< details "AB测试有哪些应用场景？" "A/B测试">}}
**AB测试适用的场景**
- **产品迭代**：比如UI界面优化、产品功能增加或者改版、流程增加或者删除等
- **算法优化**：比如搜索、推荐、精准广告等算法的优化
- **营销/运营策略优化**：比如内容的筛选、时间的筛选、人群的筛选、运营玩法的筛选等

<br/>

**AB测试不适用的场景**
- **原始创新方案且全量投放**：比如公司更新logo，这种要给所有用户看的场景不能做AB测试
- **用户体量不大的业务**：主要是样本量不够，难以支撑A/B测试所需样本量

{{< /details >}}

### 有没有接触过A/B-test，请说说你对A/B测试的理解

{{< details "有没有接触过AB-test，请说说你对AB测试的理解" "A/B测试">}}
**A/B测试流程**：
1. 确定实验目标和假设
2. 确定观测指标
3. 样本量的计算
4. 流量分割
5. 实验周期的计算
6. 实施测试
   - 灰度
   - **埋点设计**
7. 效果评估验证

<br/>

如何配合
遇到什么难题
如何解决

对AB测试的理解：


{{< /details >}}


### 你怎么理解A/B测试中的第一、二类错误？
{{< details "你怎么理解A/B测试中的第一、二类错误？" "A/B测试">}}

**第一类错误（弃真错误）**: 原假设为真时错误地拒绝原假设
- **实际业务场景**：功能改动实际无差异（为真），但误认为有显著收益而上线该功能

<br/>

**第二类错误（存伪错误）**: 原假设为假时错误地接受原假设
- **实际业务场景**：功能改动实际有效是好产品（为假），但误判为无效而放弃上线

<br/>

在实际工作中，我认为**第一类错误是更加不能接受的**：

因为，在商业世界里，**一个坏产品的上线带来的损失可能是巨大的，所以我们宁愿放弃几个好的创意好的产品，也绝不能让坏的产品上线**。如果一个坏产品上线了，不仅可能会极大程度的影响当时的用户体验，还有可能对以后的日活、留存等指标造成更大的影响。本身在实际工作中，把留存或者日活提升一个百分点都已经是非常耗时耗力的事情了，一个坏产品的上线可能一瞬间就能让留存下降好几个百分点。
{{< /details >}}

## 为什么

### 为什么要做A/B测试？A/B测试有什么好处？有什么科学依据？
{{< details "为什么要做A/B测试？A/B测试有什么好处？有什么科学依据？" "A/B测试">}}

回答要点：A/B测试的目的/好处+理论基础

**A/B测试的目的/好处**：
首先我认为
- 功能设计者是有**个人思维的局限性**
- **全量用户具有不可调研性**
这就会导致一个问题一个功能的预期效果可能与实际上线后的效果存在一定的差异，这个差异到底有多大、我们能不能接受，最后要不要上线这个功能，这些都是需要进行决断的

<br/>

**理论基础**：
AB测试是一个基于统计的假设检验过程，首先对实验组和对照组的关系提出假设，然后计算两组数据的差异并确定该差异是否存在统计上的显著性，最后依据数据结果对假设做出判断

这个过程可以很大程度上避免我们拍脑袋决策，科学量化优化方案的效果
{{< /details >}}

### A/B测试成本很高，每个调整都需要做A/B测试吗？
{{< details "A/B测试成本很高，每个调整都需要做A/B测试吗？" "A/B测试">}}

回答要点：说出你理解的AB测试发起的条件，比如改动的影响程度、收益

**需要从源头了解功能改动的重要性、影响程度等**：

- **如果重要性或者影响程度很大，那么是一定要做AB测试的**
  比如一个大型营销活动的落地页设计，就非常值得做AB测试，首先是这个页面的改动有可能直接影响最后的销售额，因为这个页面很大程度决定了用户是否对你的产品感兴趣，并为此而付费

  此外，一个大型营销活动一定是投入了大量的人力物力财力，每一个细节都有可能决定最终的结果，所以前期一定要尽可能筛出最优的方案
- **如果只是验证一个小按钮或者一个小改动，并且这个改动并不会对用户体验、活动结果、最终收益产生巨大影响的时候，就可以选择不上AB测试了**
  比如在界面上按设置一个开关，用户可以通过开关的形式自行决定采用哪一种方式，最后我们可以通过这个开关的相关指标来判断用户对于哪一种形式有更大的倾向性或者可以做一些用户调研、比如通过访谈或者说设计问卷的形式，去搜集一些用户的反馈等等

{{< /details >}}

## 怎么做
### AB测试的主要流程是什么？
{{< details "A/B测试的主要流程是什么？" "A/B测试">}}

回答要点：A/B测试的主要流程+业务场景

**A/B测试的主要流程**：

1. **确定实验目标和假设**：首先需要和相关的产品或者项目经理确定这个实验所要验证的改动点是什么
2. **确定观测指标**：数据分析师需要设计实验中所需要去观测的一些核心指标，比如点击率、转化率等
3. **样本量的计算**：计算实验所需的最少样本量，由于实验样本越大结果越可信但是对用户的不良影响就越大，所以需要计算能够显著地证明策略有效的最少样本量
4. **流量分割**：设计流量分割策略，根据实验需要对样本流量进行分流分层，保证样本的随机和均匀分布，避免出现辛普森悖论
5. **实验周期的计算**：结合目前的日均活跃的用户量，计算实验持续的时间周期
6. **实施测试**：和产品经理、开发人员确认可以开始实验
   - **灰度测试**：目的就是为了验证这个改动并不会造成特别极端的影响
   - **埋点设计**：检验数据埋点是否跑通，是否能够成功搜集到数据
7. **效果评估验证**：对实验的结果进行显著性检验以及最终的效果评估验证，实验结果主要分成有效和无效两种
   - **有效的结果**：即成功通过实验提升了产品的转化率，可以把优胜的版本正式推送给全部客户，实现产品用户有效增长
   - **无效的结果**：可转化为团队的经验，避免再犯同样的错误

{{< /details >}}

### 选择A/B实验的样本时，需要注意什么
{{< details "选择AB实验的样本时，需要注意什么？" "A/B测试">}}

回答要点：A/B测试的主要流程+业务场景

**选择A/B实验样本的注意事项**：

- **满足最小样本量**：样本量既不能太少（影响可信度）也不能太多（影响用户体验）
  - **影响样本量选择的四个因素**：
    - **显著性水平（$α$）**：显著性水平越低，对AB测试结果的要求也就越高，越需要更大的样本量来确保精度
    - **统计功效（$1-β$）**：统计功效意味着避免犯二类错误的概率，统计功效越大，需要的样本量也越大
    - **均值差异（$δ$）**：如果真实值和测试值的均值差别巨大，也不太需要多少样本，就能达到统计显著
    - **标准差（$σ$）**：标准差越小，代表两组差异的趋势越稳定，越容易观测到显著的统计结果
  - **每组所需最小样本量**：
    $$
    N=\frac{\sigma^2}{\delta^2}(Z_{1-\frac{\alpha}{2}}+Z_{1-\beta})^2
    $$
    实际业务中在不影响用户体验的前提下，可以比最小样本数多一些
- **时间一致**：必须选择同一时间段内的用户，避免时间因素干扰
- **特征一致**：确保实验组和对照组用户特征分布相似
- **随机化**：可通过随机抽样实现样本代表性
{{< /details >}}

### 介绍一下A/B测试，以及所需样本量计算公式是什么？
{{< details "介绍一下A/B测试，以及所需样本量计算公式是什么？" "A/B测试">}}

回答要点：A/B测试的理解+公式

**A/B测试的理解**：
AB测试是一种基于统计学的实验方法，通过设置对照组和实验组，对变量进行试验，通过假设检验对不同组的结果进行检验，以检验变量是否对结果造成显著影响，从而选取最合理的方法

在产品迭代、算法迭代、运营策略优化等场景下，A/B测试能够帮助我们更加科学地进行决策

**每组所需最小样本量计算公式**：

$$
N=\frac{\sigma^2}{\delta^2}(Z_{1-\frac{\alpha}{2}}+Z_{1-\beta})^2
$$

- 显著性水平$α$为犯第一类错误的概率
- $β$为犯第二类错误的概率
- $σ$代表的是样本数据的标准差
  - 比率值：$\sigma^{2} = P_{A}(1 - P_{A}) + P_{B}(1 - P_{B})$，$P_{A}$、$P_{B}$分别是对照组和实验组的观测值
  - 绝对值：$\sigma^2=\frac{\sum_1^n(x_i-\bar{x})^2}{n-1}$， $\bar{x}$指的是样本均值，$n$为样本数
- $δ$代表的是预期实验组和对照组两组数据的差值

{{< /details >}}

### A/B测试的实验周期如何选择？需要考虑哪些因素？过长或过短有什么影响？
{{< details "A/B测试的实验周期如何选择？需要考虑哪些因素？过长或过短有什么影响？" "A/B测试">}}

**实验所需最少周期计算公式**：某时间段可以是每天，流量大可以按每小时
$$实验所需最少周期=\frac{\text{每组最小样本数}\times\text{组数量}}{\text{某时间段的访问流量}}$$ 

**实验周期选择的因素**：
1. **最小样本量**：实验周期内累计样本量必须大于最小样本量要求
2. **周末效应**：周中(工作日)和周末用户行为存在显著差异，实验周期至少需要运行完整的7天
3. **新奇效应**：重点针对老用户对改版会产生的非持久性行为，这段时间置信度较低，需适当拉长试验周期
<br/>

**实验周期选择的影响**：
- **过长**：导致实验迭代的效率变低
- **过短**：导致用户体验受影响，实验不置信
{{< /details >}}

### 如何进行合理的流量分割？
{{< details "如何进行合理的流量分割？" "A/B测试">}}

**流量分割方法**：
- **分流（用户互斥）**：按地域/性别/年龄等将用户均匀分组，一个用户仅出现在一个组
  
   组间互斥（组1+组2=100%流量）
- **分层（用户正交）**:同一批流量可分布在多个无业务关联的实验层
  
  每一层用完的流量进入下一层时，一定均匀的重新分配
- **分流分层模型**：分流+分层
   - **分流阶段**：将总流量分为互斥的组1和组2（各50%）
   - **分层阶段**：组2流量可复用至B1/B2/B3层
   - **扩展应用**：B1层可再分为互斥的B1-1/B1-2/B1-3

{{< /details >}}

### 如何验证你的改进办法有效果？如何确定此功能上线收益？
{{< details "如何验证你的改进办法有效果？如何确定此功能上线收益？" "A/B测试">}}

**通过假设检验对关键性指标进行检验**：比如：点击率、留存率、复购率、转化率、人均时长等（**样本均值的t检验**和**样本比例的z检验**）
- **结论置信**：得到A/B case哪个指标更好（有显著性差异）
- **结论置信**：进一步找问题

<br/>

**计算每组投入产出比**（$\text{ROI} = \frac{\text{收益} - \text{成本}}{\text{成本}}$）对比哪组case有效：
- **成本**：每个实验组成本可以直接计算
- **收益**：和对照组相比较，假定以DAU作为收益指标，需要假设不做运营活动： 
  - $\text{实验组DAU}_\text{假设不做活动} = 对照组DAU \times \frac{\text{实验组流量}}{\text{对照组流量}}$
  - $\text{实验组收益} = \text{实验组DAU} - \text{实验组DAU}_\text{假设不做活动}$
- 一般**有活动**相比无活动，留存、人均时长等各项指标均会更**显著**
{{< /details >}}

### 请分析下A/B-test的结果统计显著不等于实际显著，你怎么看？
{{< details "请分析下A/B-test的结果统计显著不等于实际显著，你怎么看？" "A/B测试">}}
1. **统计学上显著，实际不显著**：可能选取的样本量过大，导致和总体数据量差异很小
    举例：对应到我们的互联网产品实践当中，我们做了一个改动，APP的启动时间的优化了0.001秒，这个数字可能在统计学上对应的P值很小（统计学上是显著的），但是在实际使用过程中，对于用户来说，0.001秒的差异太微小了，是感知不出来的。那么这样一个显著的统计差别，其实对我们来说是没有太大的实际意义的
2. **统计学上不显著，实际显著**：一般我们处理通用的方式是将这个指标去拆分成每天去观察
    如果指标的变化曲线每天实验组都高于对照组，即使它在统计学上说是不显著的，我也认为在这样一个观测周期内，实验组的关键指标表现优于对照组的，那么结合这样一个观测，我们最终也可以得出这个优化可以上线的结论
{{< /details >}}

### 若在A/B测试中发现实验组核心指标明显优于对照组，那这个优化就一定能够上线吗？
{{< details "若在A/B测试中发现实验组核心指标明显优于对照组，那这个优化就一定能够上线吗？" "A/B测试">}}
**不一定，需要实际情况实际分析**

- **举例**：提升产品视觉展现效果的UI优化，代价是增加用户等待内容展现的时间
- **影响**：可能导致用户耐心下降，对其他部门产生负向影响，最终可能造成公司整体收入下降
- **总结**：需要全面评估所有相关指标的变动，同时评估收益和损失，才可以确认这个优化可以上线

{{< /details >}}

## 场景题
### 美团打算从外卖的主营业务拓展到其他业务中，比如美团跑腿。公司考虑向用户发送APP内的推送通知来推广这一个新业务。你会如何设计和分析一个A/B测试来决定是否应该推出这个推送通知？
{{< details "美团打算从外卖的主营业务拓展到其他业务中，比如美团跑腿。公司考虑向用户发送APP内的推送通知来推广这一个新业务。你会如何设计和分析一个A/B测试来决定是否应该推出这个推送通知？" "A/B测试">}}
1. **询问问题细节**，与面试官产生互动，以更好地理解业务目标和产品特性细节
   - **我**：我想先确认一下我对问题背景，类似这样的功能可能会有多个不同的业务目标——比如增加新用户获取、增加这项业务的转化率、增加该业务订单数量或增加总订单销售额
   - **面试官**：通过App推送通知，我们主要是想提高这项新业务的转化率——即**在所有登录或活跃用户中，该新业务下单用户的占比**
   - **我**：好的，那现在我可以了解更多关于通知的内容么？比如推送的信息是什么？目标受众是谁？
   - **面试官**：目前我们不提供任何折扣，我们只是想让他们知道，我们有了一项新的业务，他们可以开始使用，如果实验成功，我们打算向所有用户推广出通知
   - **我**：好的，谢谢介绍，现在，我准备深入研究实验的细节
2. **陈述业务假设和定义要评估的指标**<br/>
    除了**主要指标**之外，还要考虑**次要指标**和**护栏指标**
    
    - **我**：我们的期望是，如果我们发送App推送通知，那么新业务的每日订单数量将会增加，转化率也会增加，所以，**原假设$H_0$：发送App通知，转化率没有任何变化**
    - **我**：
      - **主要指标**：**转化率**，因为通知的目标是提高新业务的转化率
      - **次要指标**：**平均订单价值**，因为转化率可能会上升，但如果平均订单价值下降、从而导致整体收益下降的话，那这也不是我们希望看到的
      - **护栏指标**：**产品的性能指标**，不希望我们做的这个A/B测试影响到它们
    - **面试官**：我同意你对主要指标的选择，但当前的场景下，你可以忽略次要指标，在护栏指标方面，你是正确的——当涉及到App时，美团希望对任何功能或发行版本保持谨慎态度，因为我们知道安装了App的用户的生命周期价值（LTV）要高得多，我们要尽量避免用户卸载App
    - **我**：好的，那当前我们就可以把**卸载的百分比**作为我们的护栏指标

    **护栏指标**是用来帮助我们戒备成功指标给予错误信号的情况，不直接表示实验组是否成功，但是从提供另一种维度来描述实验而提供了更全面的分析
      - 可以是**产品的性能指标**：比如，多少搜索成功完成，平均耗时多少？虽然这些度量并不完全决定是否发布新的搜索引擎，但是如果我们发现它的表现非常差，即使成功指标（相关性）有些许的提高，我们往往也不会发布新的产品
      - 也可以是**产品不直接影响的商业价值指标**：在做用户增长实验时，也可以将用户体验作为护栏指标，虽然大部分的新产品和新功能都不应该影响用户体验，但是将它们加入护栏指标可以对实验结果更有信心
3. **选择显著性水平、统计功效，计算所需的样本大小和实验周期**<br/>
    对统计概念和最小样本量的计算以及实验周期计算的掌握程度，你是否考虑了**各类因素对实验有效性的影响**，比如：网络效应经常影响双边市场类的公司或社交网络、工作日效应、季节性/周期性或新奇效应
      - **网络效应**：经济学用语，指的是某种产品对一名用户的价值取决于使用该产品的其他用户的数量
      - **工作日效应**：周中和周末的用户行为表现存在着一定的差异
      - **新奇效应**：一个新事物/新产品/新功能，在最初被用户熟知的时候会有提高的趋势（相对于平稳之后）
    - **我**：定义好原假设以及后续要评估的指标之后，就可以正式进入实验设计阶段了，在当前场景中是否需要考虑网络效应呢？考虑**网络效应**，我们将需要选择不同于我们通常所做的随机单位，比如**基于地理的随机化**、**基于时间的随机化**、**网络集群的随机化**或**以网络自我为中心的随机化**等等
    - **面试官**：为了节省时间，这里假设不存在网络效应，继续
    - **我**：假设没有网络效应，那么实验的随机单位就是用户，我们将随机选择用户，并将他们分配到实验和控制组中，实验组将收到通知，控制组将不会收到任何通知，接下来，需要**计算样本大小**和**实验持续时间**，为此我需要输入一些指标：
      - **基线转化**：这是在进行更改之前对照组已经存在的转化
      - **最小可检测差异**：在实施和维护功能成本合理的情况下，实现理想结果所需要的的提升
      - **显著性水平**：当原假设成立时，拒绝原假设的概率
      - **统计功效**：即测试正确拒绝原假设的概率（避免犯第二类错误的概率）
    - **我**：通常会选择**5%的显著性水平**和**80%的统计功效**，再加上基线转化和期望提升的转化，带入到最小样本量计算公式中就可以计算出每一组所需要的最小样本量了，最小样本量计算公式如下：
        $$N = \frac{\sigma^2}{\delta^2}(Z_{1-\frac{\alpha}{2}} + Z_{1-\beta})^2$$
        - **显著性水平$α$为犯第一类错误的概率**
        - **$β$为犯第二类错误的概率**
        - **$σ$代表的是样本数据的标准差**
          - **比率值**：$\sigma^{2} = P_{A}(1 - P_{A}) + P_{B}(1 - P_{B})$，$P_{A}$、$P_{B}$分别是对照组和实验组的观测值
          - 绝对值：$\sigma^2=\frac{\sum_1^n(x_i-\bar{x})^2}{n-1}$， $\bar{x}$指的是样本均值，$n$为样本数
        - **$δ$代表的是预期实验组和对照组两组数据的差值**
    - **面试官**：好的，现在加入通过分析我们知道了每个组需要10000个用户的样本大小，你会怎么计算测试的持续时间？
    - **我**：我们需要知道每天登录到APP的用户数量
    - **面试官**：假设我们每天有1万名用户登录这个App
    - **我**：在这种情况下，我们至少需要2天来进行实验——我是通过将**控制组和实验组的总样本量除以每日用户数量**得出这个结论的，但是，在确定期限时，我们还应该考虑其他因素，比如：
      - **工作日效应**：可能会在周末和工作日有不同的用户群，因此运行足够长的时间来捕捉每周周期是很重要的
      - **季节性效应**：需要考虑到的是，有些时间用户行为可能不同，比如节假日
      - **新奇效应**：当你引入一个新功能，特别是一个很容易被注意到的功能时，一开始它会吸引用户去尝试它。所以实验可能在一开始表现得很好，但随着时间的推移，效果会迅速下降。
      - **外部效应**：例如，假设市场运行得很好，更多的人可能会因为期望获得高回报而忽略通知，这将使我们从实验中得出错误的结论
      - 综上所述，我建议实验至少进行一周
    - **面试官**：好的，听起来还算合理，你如何分析测试结果?
4. **分析结果并得出结论**：在不同情况下使用的适当统计检验的知识（例如，**样本均值的t检验**和**样本比例的z检验**）；**考虑随机性**（这会给你加一些印象分）；**提供最终的建议**（或实现该建议的框架）
   - **我**：
     - **考虑随机性**：应该在分配实验组和对照组时，考虑随机性是否正确，可以查看一些不希望受到测试影响的基线指标，并通过比较这些指标在两组之间的直方图或密度曲线来进行对比，如果没有区别，我们可以得出结论，随机性是正确的
     - **所有指标（包括主要指标和护栏指标）的显著性检验**：主要指标（转化率）和护栏指标（卸载率）都是比率，可以用z检验来检验统计的显著性（python）
     - **最终建议**：
       - **转化率有了显著的增长，卸载率也没有受到负面影响，我建议执行测试**
       - 转化率有了显著的增长，卸载率受到了负面影响，我建议不要执行测试
       - 转化率在统计意义上没有显著的提高，我建议不要执行测试

{{< /details >}}



