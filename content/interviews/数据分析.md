---
title: "数据分析"
date: 2024-11-10
---
# 数据分析基础

{{< details "数据分析思维是什么？怎么去验证？">}}

数据分析思维是**使用数据分析技能解决问题**

通过三个问题验证是否具备数据分析思维：

- 到底要怎么分析问题？
- 到底分析出什么结论？
- 这个结论有什么用？
  {{< /details >}}

# 业务指标与模型

{{< details "**什么是RFM模型？如何应用？**" "用户分析" >}}

RFM模型是一种经典的用户价值评估模型，通过三个维度对用户进行分群和价值评估：

**三个维度**：

- **R (Recency - 最近一次消费)**：距离最后一次购买的时间，值越小越好

  - 反映用户的活跃度和流失风险
  - 最近购买的用户更可能再次购买
- **F (Frequency - 消费频次)**：一定时间内的购买次数

  - 反映用户的忠诚度和粘性
  - 频次越高说明用户越依赖产品
- **M (Monetary - 消费金额)**：一定时间内的总消费金额

  - 反映用户的价值贡献
  - 金额越高用户价值越大

**评分方法**：

将每个维度按分位数划分为5个等级（1-5分），组合成RFM评分：

- 如555表示：最近购买、高频次、高金额 → 最有价值客户
- 如155表示：最近购买、低频次、低金额 → 新用户/潜力客户
- 如511表示：很久未购买、高频次、低金额 → 流失预警

**用户分群策略**：

**RFM用户分群对比**：

| 用户类型               | RFM特征                               | 用户画像                     | 运营策略                                                                                        | 典型案例           |
| ---------------------- | ------------------------------------- | ---------------------------- | ----------------------------------------------------------------------------------------------- | ------------------ |
| **重要价值客户** | R高F高M高``（555、554、544）   | 最近消费、购买频繁、金额高   | • VIP专属服务``• 优先体验新品``• 个性化推荐``• 忠诚度奖励              | 品牌忠实用户       |
| **重要发展客户** | R高M高F中低``（525、535、515） | 最近消费、金额高、但频次不高 | • 提升购买频次``• 会员权益吸引``• 定期触达提醒``• 建立购买习惯         | 新注册大额消费用户 |
| **重要挽留客户** | R低F高M高``（255、155、154）   | 很久未消费、但曾经高价值     | • 流失预警``• 大力度召回（优惠券）``• 问卷调研流失原因``• 重建品牌连接 | 沉睡的老VIP        |
| **一般用户**     | 中等分值``（333、233、323）    | 各项指标中等                 | • 促进活跃``• 提升客单价``• 交叉销售``• 常规营销                       | 普通消费者         |
| **新用户**       | R高F低M低``（511、521、522）   | 最近首次消费、金额小         | • 新手引导``• 首单优惠``• 培养忠诚度                                           | 刚注册用户         |
| **流失用户**     | R低F低M低``（111、112、121）   | 很久未消费、历史价值也低     | • 成本控制``• 低成本触达``• 放弃或重激活                                       | 僵尸用户           |

**详细案例**：

{{< tabs "高价值用户,发展型用户,挽留型用户,一般用户" >}}

**重要价值客户（RFM都高）**

特征：555、554、544、545等

- 最近有消费
- 购买频繁
- 消费金额高

运营策略：

- 提供VIP专属服务
- 优先体验新品
- 个性化推荐
- 忠诚度奖励计划

|||

**重要发展客户（R高M高F中低）**

特征：525、535、515等

- 最近有消费
- 消费金额高
- 但频次不高

运营策略：

- 提升购买频次
- 会员权益吸引
- 定期触达提醒
- 建立购买习惯

|||

**重要挽留客户（R低FM高）**

特征：255、155、154等

- 很久未消费
- 但曾经是高价值用户

运营策略：

- 流失预警
- 大力度召回（优惠券）
- 问卷调研流失原因
- 重建品牌连接

|||

**一般用户（中等分值）**

特征：333、233、323等

- 各项指标中等

运营策略：

- 促进活跃
- 提升客单价
- 交叉销售
- 常规营销

{{< /tabs >}}

**应用场景**：

- 精准营销：针对不同群体设计营销活动
- 用户预警：识别即将流失的高价值用户
- 资源分配：将资源集中在高价值用户上
- 效果评估：追踪运营活动后用户的RFM变化

{{< /details >}}

{{< details "**什么是漏斗分析？如何找到关键流失点？**" "埋点分析" >}}

漏斗分析是将用户完成某个目标的多步骤流程可视化，分析每个环节的转化率和流失率，找出优化机会。

**漏斗分析的核心指标**：

- **转化率**：从上一步到下一步的用户转化比例
- **流失率**：在某个环节流失的用户比例 = 1 - 转化率
- **整体转化率**：从第一步到最后一步的总转化率
- **平均转化时长**：用户完成整个流程的平均时间

**典型的电商购买漏斗**：

```
首页访问 (100%)
    ↓  45%转化
商品浏览 (45%)
    ↓  40%转化
加入购物车 (18%)
    ↓  50%转化
提交订单 (9%)
    ↓  67%转化
支付成功 (6%)
```

**找到关键流失点的方法**：

1. **环节转化率对比**

   - 计算每个环节的转化率
   - 识别转化率异常低的环节
   - 如上例中"加购→下单"转化率仅50%，是最大流失点
2. **流失用户数对比**

   - 计算每个环节的绝对流失用户数
   - 流失用户数 = 上一环节人数 × (1 - 转化率)
   - 优先优化流失用户数最多的环节
3. **行业benchmark对比**

   - 与行业平均水平对比
   - 低于行业水平的环节需要重点关注
4. **用户行为分析**

   - 分析流失用户在该环节的行为
   - 查看运费、反复查看价格、长时间停留等行为
   - 推断流失原因

**优化策略**：

{{< admonition type="tip" title="漏斗优化的优先级判断" collapse="false" >}}

考虑三个因素：

1. **流失比例**：流失率越高优先级越高
2. **影响规模**：流失绝对人数越多优先级越高
3. **优化成本**：改进成本越低优先级越高

综合评估：影响 = 流失人数 × 人均价值 - 优化成本

{{< /admonition >}}

**时间窗口设置**：

不同场景需要设置不同的时间窗口：

- **实时漏斗**（1小时内）：适用于短流程，如注册、支付
- **会话漏斗**（单次访问）：适用于一次完成的流程
- **天级漏斗**（1-7天）：适用于需要考虑时间的长决策流程

时间窗口过短会低估转化率，过长会高估转化率

{{< /details >}}

{{< details "**什么是留存率？如何分析留存曲线？**" "数据分析" >}}

留存率是衡量产品粘性和用户价值的核心指标，反映用户在一段时间后继续使用产品的比例。

**留存率定义**：

N日留存率 = 第N天仍活跃的用户数 / 第0天的新增用户数 × 100%

**常见留存指标**：

- **次日留存**（D1 Retention）：第1天回访的用户比例，反映首日体验
- **3日留存**（D3）：第3天回访比例，反映短期粘性
- **7日留存**（D7）：第7天回访比例，进入第一个稳定期
- **30日留存**（D30）：第30天回访比例，反映长期价值
- **周留存**：第N周的回访比例
- **月留存**：第N月的回访比例

**留存曲线分析**：

一个典型的留存曲线呈现几个阶段：

```
100% (D0新增)
  ↓
 42% (D1) - 快速流失期
  ↓
 30% (D3) - 第一平台期
  ↓
 22% (D7) - 第二下降期
  ↓
 12% (D30) - 稳定期
```

**关键节点分析**：

{{< tabs "快速流失期,第一平台期,稳定期,Magic Number" >}}

**0-3天：快速流失期**

特点：流失率最高（50-70%）
原因：

- 产品不符合预期
- 未体验到核心价值
- 竞品分流

优化方向：

- 强化新手引导
- 突出核心价值
- 降低使用门槛
- 首日激励机制

|||

**3-7天：第一平台期**

特点：流失趋缓，进入第一个稳定期
原因：

- 用户开始养成习惯
- 但习惯尚不稳固

优化方向：

- Push提醒
- 每日签到
- 新手任务
- 社交绑定

|||

**7-30天：稳定期形成**

特点：留存趋于平稳
原因：

- 用户已形成使用习惯
- 这部分是产品核心用户

优化方向：

- 提升活跃度
- 付费转化
- 社交传播
- 会员权益

|||

**Magic Number分析**

寻找与高留存强相关的关键行为：

经典案例：

- Facebook：10天内添加7个好友
- Twitter：关注30个账号
- Dropbox：上传1个文件

方法：

1. 统计不同行为次数的用户留存率
2. 找到留存率显著提升的拐点
3. 引导用户完成该行为

{{< /tabs >}}

**留存率的重要性**：

用户生命周期价值（LTV）与留存率直接相关：

LTV = ARPU × 平均留存月数

如果月留存率从20%提升到30%：

- 平均留存月数从1.25月增加到1.43月
- LTV提升14%

{{< admonition type="note" title="留存率优化建议" collapse="false" >}}

1. **分群分析留存**：不同用户群体的留存差异很大

   - 新老用户留存对比
   - 不同渠道用户留存对比
   - 不同行为用户留存对比
2. **追踪Cohort留存**：按注册时间分组追踪

   - 观察产品迭代对留存的影响
   - 避免整体留存率的季节性误导
3. **关注留存曲线形态**：

   - 微笑曲线：初期流失后回升 → 好产品
   - 快速下降后平稳 → 正常产品
   - 持续下降 → 产品有问题

{{< /admonition >}}

{{< /details >}}

{{< details "**AARRR增长模型是什么？**" "数据分析" >}}

AARRR模型（海盗指标）是增长黑客领域最经典的分析框架，将用户生命周期分为五个阶段，每个阶段有不同的核心指标和优化重点。

**五个阶段**：

**1. Acquisition - 获取用户**

核心目标：吸引潜在用户访问产品

关键指标：

- 新增用户数
- 各渠道流量
- 获客成本（CAC）
- 注册转化率

分析重点：

- 渠道效果对比（质量vs成本）
- 落地页转化率
- 获客ROI

**2. Activation - 激活用户**

核心目标：让用户体验到产品核心价值（Aha Moment）

关键指标：

- 激活率
- 新手引导完成率
- 核心功能使用率
- 首日行为深度

分析重点：

- 定义激活标准（如：发布第一条内容、添加第一个好友）
- 优化新手引导流程
- 缩短Aha Moment的时间

**3. Retention - 留存用户**

核心目标：让用户持续回访使用产品

关键指标：

- 次日留存率
- 7日留存率
- 30日留存率
- 月活/日活

分析重点：

- 留存曲线分析
- Magic Number识别
- 流失原因分析
- 召回策略

**4. Revenue - 获取收入**

核心目标：将用户转化为付费用户，产生收入

关键指标：

- 付费率
- ARPU（人均收入）
- ARPPU（付费用户人均收入）
- LTV（用户生命周期价值）

分析重点：

- 付费转化漏斗
- 定价策略
- 付费用户画像
- 提升客单价

**5. Referral - 推荐传播**

核心目标：用户自发推荐，形成病毒式增长

关键指标：

- K因子（病毒系数）
- 分享率
- NPS（净推荐值）
- 邀请转化率

分析重点：

- 分享动机设计
- 分享路径优化
- 邀请奖励机制

**AARRR应用策略**：

{{< admonition type="tip" title="不同阶段产品的AARRR重点" collapse="false" >}}

**早期产品（PMF验证期）**：

- 重点：Activation + Retention
- 目标：验证产品价值，找到核心用户
- 策略：小范围测试，快速迭代

**成长期产品**：

- 重点：Acquisition + Retention
- 目标：扩大用户规模，保持用户粘性
- 策略：优化获客渠道，提升留存率

**成熟期产品**：

- 重点：Revenue + Referral
- 目标：商业变现，自增长
- 策略：提升付费率，建立传播机制

{{< /admonition >}}

**AARRR与北极星指标**：

在AARRR框架下，需要确定一个北极星指标（North Star Metric）：

- **工具类产品**：日活跃用户数（DAU）
- **内容类产品**：内容消费时长
- **电商类产品**：GMV或订单数
- **社交类产品**：互动次数

北极星指标应该：

- 反映用户获得的核心价值
- 能够预测长期商业成功
- 可被团队直接影响

{{< /details >}}

{{< details "**用户生命周期价值（LTV）如何计算？**" "用户分析" >}}

LTV（Lifetime Value，用户生命周期价值）是指一个用户在整个生命周期内为产品带来的总收入，是评估用户价值和指导获客投入的核心指标。

**基础计算公式**：

```
LTV = ARPU × 平均生命周期月数
```

其中：

- ARPU = 总收入 / 总用户数（人均收入）
- 平均生命周期 = 1 / 月流失率

**详细计算方法**：

{{< tabs "简化法,留存法,cohort法" >}}

**简化计算法**

适用于稳定业务，快速估算

```
LTV = ARPU × (1 / 月流失率)
```

示例：

- ARPU = 50元/月
- 月流失率 = 20%
- LTV = 50 × (1/0.2) = 250元

优点：计算简单
缺点：忽略了时间价值和复杂因素

|||

**留存曲线法**

基于实际留存数据计算

```
LTV = Σ(第N月ARPU × 第N月留存率)
```

示例（计算前12个月）：

```
月份  ARPU  留存率  贡献
M1    50    100%    50
M2    50     60%    30
M3    50     40%    20
M4    50     30%    15
...
LTV = 50+30+20+15+... = 约200元
```

优点：更准确，考虑留存衰减
缺点：需要足够的历史数据

|||

**Cohort分析法**

按注册时间分组，追踪真实LTV

步骤：

1. 选择某个注册cohort（如2024年1月注册用户）
2. 追踪该组用户每月的收入贡献
3. 累加至今的总收入
4. 除以该组用户数

优点：最准确，反映真实情况
缺点：需要长期追踪，早期产品数据不足

{{< /tabs >}}

**LTV与CAC的关系**：

CAC（Customer Acquisition Cost）是获客成本，LTV/CAC是评估增长健康度的关键指标：

- **LTV/CAC > 3**：健康，获客有利润空间
- **LTV/CAC = 1-3**：需要优化，利润空间不足
- **LTV/CAC < 1**：亏损，不可持续

**提升LTV的策略**：

1. **提升ARPU**

   - 提高客单价
   - 增加购买频次
   - 交叉销售/向上销售
2. **延长生命周期**

   - 提升留存率
   - 降低流失率
   - 会员体系绑定
3. **细分用户群**

   - 识别高LTV用户特征
   - 针对性获客
   - 差异化运营

**实际应用**：

电商平台案例：

- 计算不同渠道用户的LTV
- 对比渠道的CAC
- 发现：搜索广告LTV=300，CAC=80，ROI=3.75
- 发现：社交广告LTV=150，CAC=30，ROI=5
- 策略：虽然搜索用户LTV更高，但社交渠道ROI更好，可加大投入

{{< admonition type="warning" title="LTV计算的注意事项" collapse="false" >}}

1. **时间窗口选择**：计算前12个月还是前24个月的LTV？
2. **折现率考虑**：长期收入需要考虑货币时间价值
3. **用户分层**：不同用户群体的LTV差异很大，不要只看平均值
4. **动态调整**：产品迭代会影响LTV，需要定期更新
5. **成本归因**：CAC应该包含哪些成本？（渠道费用、营销费用、人力成本？）

{{< /admonition >}}

{{< /details >}}

{{< details "**常见的电商核心指标有哪些？**" "数据分析" >}}

电商数据分析涉及多个维度的指标，每个指标反映业务的不同侧面。

**GMV相关指标**：

- **GMV（Gross Merchandise Volume）**：成交总额，包含未支付订单

  - 计算：GMV = 订单数 × 平均订单金额
  - 反映平台整体规模
- **实际成交额**：已支付订单的总金额

  - 更真实反映业务收入
- **客单价（AOV - Average Order Value）**：平均每个订单的金额

  - 计算：AOV = 总成交额 / 订单数
  - 反映用户消费能力

**流量指标**：

- **UV（Unique Visitor）**：独立访客数
- **PV（Page View）**：页面浏览量
- **PV/UV**：人均浏览页面数，反映用户活跃度

**转化指标**：

- **整体转化率**：下单用户数 / 访问用户数
- **加购转化率**：加购用户数 / 访问用户数
- **支付转化率**：支付用户数 / 下单用户数

**用户指标**：

- **新客/老客占比**
- **复购率**：再次购买的用户占比
- **购买频次**：平均每个用户的购买次数

**商品指标**：

- **SKU数**：商品种类数
- **动销率**：有销售的SKU占比
- **库存周转率**：商品销售速度

**运营效率指标**：

- **退货率**：退货订单数 / 总订单数
- **物流时效**：发货到签收的平均时长
- **客服响应时间**

{{< /details >}}

# A/B测试

## 是什么

### 请描述一下什么是A/B-test？

{{< details "请描述一下什么是A/B-test？" "A/B测试">}}
定义类回答技巧：专业定义 + 场景结合

**统计学定义**：

- A/B测试是一种基于统计学的实验方法
- 通过设置对照组和实验组对变量进行试验
- 然后通过假设检验对不同组的结果进行检验
- 判断变量是否对最终结果造成显著影响
- 从而帮助选取最合理的方法

<br/>

**业务场景应用**:

- AB测试是为同一目标制定不同页面版本
- 将用户流量分成对应组别
- 在同一时间维度让不同组用户随机访问这些版本
- 通过埋点设计收集各群组的用户体验和业务数据
- 分析评估出最优版本并正式采用
  {{< /details >}}

### A/B测试的核心原理是什么？

{{< details "A/B测试的核心原理是什么？" "A/B测试">}}
**A/B测试本质就是一个基于统计的假设检验过程**

1. 通过**随机合理分流**，设置对照组和实验组
2. 通过**控制变量法**，观察两组用户在一段时间内的表现
3. 通过**假设检验**，分析结果是否有显著差异从而判断改动是否有效可执行

<br/>

其他理论：

- **中心极限定理**：样本量足够大时，变量均值的抽样分布都近似于正态分布
- **小概率事件**：小概率事件在一次实验中基本上不会发生
- **反证法**：假设检验的机制是保护原假设，所以把要拒绝的假设放在原假设的位置，如果原假设成立的条件下，小概率事件还是发生了，那么就应该推翻原假设
- **P值**：P值越小，拒绝原假设的理由就越充分

{{< /details >}}

### A/B测试有哪些应用场景？

{{< details "AB测试有哪些应用场景？" "A/B测试">}}
**AB测试适用的场景**

- **产品迭代**：比如UI界面优化、产品功能增加或者改版、流程增加或者删除等
- **算法优化**：比如搜索、推荐、精准广告等算法的优化
- **营销/运营策略优化**：比如内容的筛选、时间的筛选、人群的筛选、运营玩法的筛选等

<br/>

**AB测试不适用的场景**

- **原始创新方案且全量投放**：比如公司更新logo，这种要给所有用户看的场景不能做AB测试
- **用户体量不大的业务**：主要是样本量不够，难以支撑A/B测试所需样本量

{{< /details >}}

### 有没有接触过A/B-test，请说说你对A/B测试的理解

{{< details "有没有接触过AB-test，请说说你对AB测试的理解" "A/B测试">}}
**A/B测试流程**：

1. 确定实验目标和假设
2. 确定观测指标
3. 样本量的计算
4. 流量分割
5. 实验周期的计算
6. 实施测试
   - 灰度
   - **埋点设计**
7. 效果评估验证

<br/>

如何配合
遇到什么难题
如何解决

对AB测试的理解：

{{< /details >}}

### 你怎么理解A/B测试中的第一、二类错误？

{{< details "你怎么理解A/B测试中的第一、二类错误？" "A/B测试">}}

**第一类错误（弃真错误）**: 原假设为真时错误地拒绝原假设

- **实际业务场景**：功能改动实际无差异（为真），但误认为有显著收益而上线该功能

<br/>

**第二类错误（存伪错误）**: 原假设为假时错误地接受原假设

- **实际业务场景**：功能改动实际有效是好产品（为假），但误判为无效而放弃上线

<br/>

在实际工作中，我认为**第一类错误是更加不能接受的**：

因为，在商业世界里，**一个坏产品的上线带来的损失可能是巨大的，所以我们宁愿放弃几个好的创意好的产品，也绝不能让坏的产品上线**。如果一个坏产品上线了，不仅可能会极大程度的影响当时的用户体验，还有可能对以后的日活、留存等指标造成更大的影响。本身在实际工作中，把留存或者日活提升一个百分点都已经是非常耗时耗力的事情了，一个坏产品的上线可能一瞬间就能让留存下降好几个百分点。
{{< /details >}}

## 为什么

### 为什么要做A/B测试？A/B测试有什么好处？有什么科学依据？

{{< details "为什么要做A/B测试？A/B测试有什么好处？有什么科学依据？" "A/B测试">}}

回答要点：A/B测试的目的/好处+理论基础

**A/B测试的目的/好处**：
首先我认为

- 功能设计者是有**个人思维的局限性**
- **全量用户具有不可调研性**
  这就会导致一个问题一个功能的预期效果可能与实际上线后的效果存在一定的差异，这个差异到底有多大、我们能不能接受，最后要不要上线这个功能，这些都是需要进行决断的

<br/>

**理论基础**：
AB测试是一个基于统计的假设检验过程，首先对实验组和对照组的关系提出假设，然后计算两组数据的差异并确定该差异是否存在统计上的显著性，最后依据数据结果对假设做出判断

这个过程可以很大程度上避免我们拍脑袋决策，科学量化优化方案的效果
{{< /details >}}

### A/B测试成本很高，每个调整都需要做A/B测试吗？

{{< details "A/B测试成本很高，每个调整都需要做A/B测试吗？" "A/B测试">}}

回答要点：说出你理解的AB测试发起的条件，比如改动的影响程度、收益

**需要从源头了解功能改动的重要性、影响程度等**：

- **如果重要性或者影响程度很大，那么是一定要做AB测试的**
  比如一个大型营销活动的落地页设计，就非常值得做AB测试，首先是这个页面的改动有可能直接影响最后的销售额，因为这个页面很大程度决定了用户是否对你的产品感兴趣，并为此而付费

  此外，一个大型营销活动一定是投入了大量的人力物力财力，每一个细节都有可能决定最终的结果，所以前期一定要尽可能筛出最优的方案
- **如果只是验证一个小按钮或者一个小改动，并且这个改动并不会对用户体验、活动结果、最终收益产生巨大影响的时候，就可以选择不上AB测试了**
  比如在界面上按设置一个开关，用户可以通过开关的形式自行决定采用哪一种方式，最后我们可以通过这个开关的相关指标来判断用户对于哪一种形式有更大的倾向性或者可以做一些用户调研、比如通过访谈或者说设计问卷的形式，去搜集一些用户的反馈等等

{{< /details >}}

## 怎么做

### AB测试的主要流程是什么？

{{< details "A/B测试的主要流程是什么？" "A/B测试">}}

回答要点：A/B测试的主要流程+业务场景

**A/B测试的主要流程**：

1. **确定实验目标和假设**：首先需要和相关的产品或者项目经理确定这个实验所要验证的改动点是什么
2. **确定观测指标**：数据分析师需要设计实验中所需要去观测的一些核心指标，比如点击率、转化率等
3. **样本量的计算**：计算实验所需的最少样本量，由于实验样本越大结果越可信但是对用户的不良影响就越大，所以需要计算能够显著地证明策略有效的最少样本量
4. **流量分割**：设计流量分割策略，根据实验需要对样本流量进行分流分层，保证样本的随机和均匀分布，避免出现辛普森悖论
5. **实验周期的计算**：结合目前的日均活跃的用户量，计算实验持续的时间周期
6. **实施测试**：和产品经理、开发人员确认可以开始实验
   - **灰度测试**：目的就是为了验证这个改动并不会造成特别极端的影响
   - **埋点设计**：检验数据埋点是否跑通，是否能够成功搜集到数据
7. **效果评估验证**：对实验的结果进行显著性检验以及最终的效果评估验证，实验结果主要分成有效和无效两种
   - **有效的结果**：即成功通过实验提升了产品的转化率，可以把优胜的版本正式推送给全部客户，实现产品用户有效增长
   - **无效的结果**：可转化为团队的经验，避免再犯同样的错误

{{< /details >}}

### 选择A/B实验的样本时，需要注意什么

{{< details "选择AB实验的样本时，需要注意什么？" "A/B测试">}}

回答要点：A/B测试的主要流程+业务场景

**选择A/B实验样本的注意事项**：

- **满足最小样本量**：样本量既不能太少（影响可信度）也不能太多（影响用户体验）
  - **影响样本量选择的四个因素**：
    - **显著性水平（$α$）**：显著性水平越低，对AB测试结果的要求也就越高，越需要更大的样本量来确保精度
    - **统计功效（$1-β$）**：统计功效意味着避免犯二类错误的概率，统计功效越大，需要的样本量也越大
    - **均值差异（$δ$）**：如果真实值和测试值的均值差别巨大，也不太需要多少样本，就能达到统计显著
    - **标准差（$σ$）**：标准差越小，代表两组差异的趋势越稳定，越容易观测到显著的统计结果
  - **每组所需最小样本量**：
    $$
    N=\frac{\sigma^2}{\delta^2}(Z_{1-\frac{\alpha}{2}}+Z_{1-\beta})^2
    $$

    实际业务中在不影响用户体验的前提下，可以比最小样本数多一些
- **时间一致**：必须选择同一时间段内的用户，避免时间因素干扰
- **特征一致**：确保实验组和对照组用户特征分布相似
- **随机化**：可通过随机抽样实现样本代表性
  {{< /details >}}

### 介绍一下A/B测试，以及所需样本量计算公式是什么？

{{< details "介绍一下A/B测试，以及所需样本量计算公式是什么？" "A/B测试">}}

回答要点：A/B测试的理解+公式

**A/B测试的理解**：
AB测试是一种基于统计学的实验方法，通过设置对照组和实验组，对变量进行试验，通过假设检验对不同组的结果进行检验，以检验变量是否对结果造成显著影响，从而选取最合理的方法

在产品迭代、算法迭代、运营策略优化等场景下，A/B测试能够帮助我们更加科学地进行决策

**每组所需最小样本量计算公式**：

$$
N=\frac{\sigma^2}{\delta^2}(Z_{1-\frac{\alpha}{2}}+Z_{1-\beta})^2
$$

- 显著性水平$α$为犯第一类错误的概率
- $β$为犯第二类错误的概率
- $σ$代表的是样本数据的标准差
  - 比率值：$\sigma^{2} = P_{A}(1 - P_{A}) + P_{B}(1 - P_{B})$，$P_{A}$、$P_{B}$分别是对照组和实验组的观测值
  - 绝对值：$\sigma^2=\frac{\sum_1^n(x_i-\bar{x})^2}{n-1}$， $\bar{x}$指的是样本均值，$n$为样本数
- $δ$代表的是预期实验组和对照组两组数据的差值

{{< /details >}}

### A/B测试的实验周期如何选择？需要考虑哪些因素？过长或过短有什么影响？

{{< details "A/B测试的实验周期如何选择？需要考虑哪些因素？过长或过短有什么影响？" "A/B测试">}}

**实验所需最少周期计算公式**：某时间段可以是每天，流量大可以按每小时

$$
实验所需最少周期=\frac{\text{每组最小样本数}\times\text{组数量}}{\text{某时间段的访问流量}}$$ 

**实验周期选择的因素**：
1. **最小样本量**：实验周期内累计样本量必须大于最小样本量要求
2. **周末效应**：周中(工作日)和周末用户行为存在显著差异，实验周期至少需要运行完整的7天
3. **新奇效应**：重点针对老用户对改版会产生的非持久性行为，这段时间置信度较低，需适当拉长试验周期
<br/>

**实验周期选择的影响**：
- **过长**：导致实验迭代的效率变低
- **过短**：导致用户体验受影响，实验不置信
{{< /details >}}

### 如何进行合理的流量分割？
{{< details "如何进行合理的流量分割？" "A/B测试">}}

**流量分割方法**：
- **分流（用户互斥）**：按地域/性别/年龄等将用户均匀分组，一个用户仅出现在一个组
  
   组间互斥（组1+组2=100%流量）
- **分层（用户正交）**:同一批流量可分布在多个无业务关联的实验层
  
  每一层用完的流量进入下一层时，一定均匀的重新分配
- **分流分层模型**：分流+分层
   - **分流阶段**：将总流量分为互斥的组1和组2（各50%）
   - **分层阶段**：组2流量可复用至B1/B2/B3层
   - **扩展应用**：B1层可再分为互斥的B1-1/B1-2/B1-3

{{< /details >}}

### 如何验证你的改进办法有效果？如何确定此功能上线收益？
{{< details "如何验证你的改进办法有效果？如何确定此功能上线收益？" "A/B测试">}}

**通过假设检验对关键性指标进行检验**：比如：点击率、留存率、复购率、转化率、人均时长等（**样本均值的 t 检验**和**样本比例的 z 检验**）
- **结论置信**：得到A/B case哪个指标更好（有显著性差异）
- **结论置信**：进一步找问题

<br/>

**计算每组投入产出比**（$\text{ROI} = \frac{\text{收益} - \text{成本}}{\text{成本}}$）对比哪组case有效：
- **成本**：每个实验组成本可以直接计算
- **收益**：和对照组相比较，假定以DAU作为收益指标，需要假设不做运营活动： 
  - $\text{实验组DAU}_\text{假设不做活动} = 对照组DAU \times \frac{\text{实验组流量}}{\text{对照组流量}}$
  - $\text{实验组收益} = \text{实验组DAU} - \text{实验组DAU}_\text{假设不做活动}$
- 一般**有活动**相比无活动，留存、人均时长等各项指标均会更**显著**
{{< /details >}}

### 请分析下A/B-test的结果统计显著不等于实际显著，你怎么看？
{{< details "请分析下A/B-test的结果统计显著不等于实际显著，你怎么看？" "A/B测试">}}
1. **统计学上显著，实际不显著**：可能选取的样本量过大，导致和总体数据量差异很小
    举例：对应到我们的互联网产品实践当中，我们做了一个改动，APP的启动时间的优化了0.001秒，这个数字可能在统计学上对应的P值很小（统计学上是显著的），但是在实际使用过程中，对于用户来说，0.001秒的差异太微小了，是感知不出来的。那么这样一个显著的统计差别，其实对我们来说是没有太大的实际意义的
2. **统计学上不显著，实际显著**：一般我们处理通用的方式是将这个指标去拆分成每天去观察
    如果指标的变化曲线每天实验组都高于对照组，即使它在统计学上说是不显著的，我也认为在这样一个观测周期内，实验组的关键指标表现优于对照组的，那么结合这样一个观测，我们最终也可以得出这个优化可以上线的结论
{{< /details >}}

### 若在A/B测试中发现实验组核心指标明显优于对照组，那这个优化就一定能够上线吗？
{{< details "若在A/B测试中发现实验组核心指标明显优于对照组，那这个优化就一定能够上线吗？" "A/B测试">}}
**不一定，需要实际情况实际分析**

- **举例**：提升产品视觉展现效果的UI优化，代价是增加用户等待内容展现的时间
- **影响**：可能导致用户耐心下降，对其他部门产生负向影响，最终可能造成公司整体收入下降
- **总结**：需要全面评估所有相关指标的变动，同时评估收益和损失，才可以确认这个优化可以上线

{{< /details >}}

## 场景题
### 美团打算从外卖的主营业务拓展到其他业务中，比如美团跑腿。公司考虑向用户发送APP内的推送通知来推广这一个新业务。你会如何设计和分析一个A/B测试来决定是否应该推出这个推送通知？
{{< details "美团打算从外卖的主营业务拓展到其他业务中，比如美团跑腿。公司考虑向用户发送APP内的推送通知来推广这一个新业务。你会如何设计和分析一个A/B测试来决定是否应该推出这个推送通知？" "A/B测试">}}
1. **询问问题细节**，与面试官产生互动，以更好地理解业务目标和产品特性细节
   - **我**：我想先确认一下我对问题背景，类似这样的功能可能会有多个不同的业务目标——比如增加新用户获取、增加这项业务的转化率、增加该业务订单数量或增加总订单销售额
   - **面试官**：通过App推送通知，我们主要是想提高这项新业务的转化率——即**在所有登录或活跃用户中，该新业务下单用户的占比**
   - **我**：好的，那现在我可以了解更多关于通知的内容么？比如推送的信息是什么？目标受众是谁？
   - **面试官**：目前我们不提供任何折扣，我们只是想让他们知道，我们有了一项新的业务，他们可以开始使用，如果实验成功，我们打算向所有用户推广出通知
   - **我**：好的，谢谢介绍，现在，我准备深入研究实验的细节
2. **陈述业务假设和定义要评估的指标**<br/>
    除了**主要指标**之外，还要考虑**次要指标**和**护栏指标**
  
    - **我**：我们的期望是，如果我们发送App推送通知，那么新业务的每日订单数量将会增加，转化率也会增加，所以，**原假设$H_0$：发送App通知，转化率没有任何变化**
    - **我**：
      - **主要指标**：**转化率**，因为通知的目标是提高新业务的转化率
      - **次要指标**：**平均订单价值**，因为转化率可能会上升，但如果平均订单价值下降、从而导致整体收益下降的话，那这也不是我们希望看到的
      - **护栏指标**：**产品的性能指标**，不希望我们做的这个A/B测试影响到它们
    - **面试官**：我同意你对主要指标的选择，但当前的场景下，你可以忽略次要指标，在护栏指标方面，你是正确的——当涉及到App时，美团希望对任何功能或发行版本保持谨慎态度，因为我们知道安装了App的用户的生命周期价值（LTV）要高得多，我们要尽量避免用户卸载App
    - **我**：好的，那当前我们就可以把**卸载的百分比**作为我们的护栏指标

    **护栏指标**是用来帮助我们戒备成功指标给予错误信号的情况，不直接表示实验组是否成功，但是从提供另一种维度来描述实验而提供了更全面的分析
      - 可以是**产品的性能指标**：比如，多少搜索成功完成，平均耗时多少？虽然这些度量并不完全决定是否发布新的搜索引擎，但是如果我们发现它的表现非常差，即使成功指标（相关性）有些许的提高，我们往往也不会发布新的产品
      - 也可以是**产品不直接影响的商业价值指标**：在做用户增长实验时，也可以将用户体验作为护栏指标，虽然大部分的新产品和新功能都不应该影响用户体验，但是将它们加入护栏指标可以对实验结果更有信心
3. **选择显著性水平、统计功效，计算所需的样本大小和实验周期**<br/>
    对统计概念和最小样本量的计算以及实验周期计算的掌握程度，你是否考虑了**各类因素对实验有效性的影响**，比如：网络效应经常影响双边市场类的公司或社交网络、工作日效应、季节性/周期性或新奇效应
      - **网络效应**：经济学用语，指的是某种产品对一名用户的价值取决于使用该产品的其他用户的数量
      - **工作日效应**：周中和周末的用户行为表现存在着一定的差异
      - **新奇效应**：一个新事物/新产品/新功能，在最初被用户熟知的时候会有提高的趋势（相对于平稳之后）
    - **我**：定义好原假设以及后续要评估的指标之后，就可以正式进入实验设计阶段了，在当前场景中是否需要考虑网络效应呢？考虑**网络效应**，我们将需要选择不同于我们通常所做的随机单位，比如**基于地理的随机化**、**基于时间的随机化**、**网络集群的随机化**或**以网络自我为中心的随机化**等等
    - **面试官**：为了节省时间，这里假设不存在网络效应，继续
    - **我**：假设没有网络效应，那么实验的随机单位就是用户，我们将随机选择用户，并将他们分配到实验和控制组中，实验组将收到通知，控制组将不会收到任何通知，接下来，需要**计算样本大小**和**实验持续时间**，为此我需要输入一些指标：
      - **基线转化**：这是在进行更改之前对照组已经存在的转化
      - **最小可检测差异**：在实施和维护功能成本合理的情况下，实现理想结果所需要的的提升
      - **显著性水平**：当原假设成立时，拒绝原假设的概率
      - **统计功效**：即测试正确拒绝原假设的概率（避免犯第二类错误的概率）
    - **我**：通常会选择**5%的显著性水平**和**80%的统计功效**，再加上基线转化和期望提升的转化，带入到最小样本量计算公式中就可以计算出每一组所需要的最小样本量了，最小样本量计算公式如下：
        $$N = \frac{\sigma^2}{\delta^2}(Z_{1-\frac{\alpha}{2}} + Z_{1-\beta})^2
$$

    -**显著性水平$α$为犯第一类错误的概率**
        - **$β$为犯第二类错误的概率**
        - **$σ$代表的是样本数据的标准差**
          - **比率值**：$\sigma^{2} = P_{A}(1 - P_{A}) + P_{B}(1 - P_{B})$，$P_{A}$、$P_{B}$分别是对照组和实验组的观测值
          - 绝对值：$\sigma^2=\frac{\sum_1^n(x_i-\bar{x})^2}{n-1}$， $\bar{x}$指的是样本均值，$n$为样本数
        - **$δ$代表的是预期实验组和对照组两组数据的差值**
    - **面试官**：好的，现在加入通过分析我们知道了每个组需要10000个用户的样本大小，你会怎么计算测试的持续时间？
    - **我**：我们需要知道每天登录到APP的用户数量
    - **面试官**：假设我们每天有1万名用户登录这个App
    - **我**：在这种情况下，我们至少需要2天来进行实验——我是通过将**控制组和实验组的总样本量除以每日用户数量**得出这个结论的，但是，在确定期限时，我们还应该考虑其他因素，比如：
      - **工作日效应**：可能会在周末和工作日有不同的用户群，因此运行足够长的时间来捕捉每周周期是很重要的
      - **季节性效应**：需要考虑到的是，有些时间用户行为可能不同，比如节假日
      - **新奇效应**：当你引入一个新功能，特别是一个很容易被注意到的功能时，一开始它会吸引用户去尝试它。所以实验可能在一开始表现得很好，但随着时间的推移，效果会迅速下降。
      - **外部效应**：例如，假设市场运行得很好，更多的人可能会因为期望获得高回报而忽略通知，这将使我们从实验中得出错误的结论
      - 综上所述，我建议实验至少进行一周
    - **面试官**：好的，听起来还算合理，你如何分析测试结果?
4. **分析结果并得出结论**：在不同情况下使用的适当统计检验的知识（例如，**样本均值的t检验**和**样本比例的z检验**）；**考虑随机性**（这会给你加一些印象分）；**提供最终的建议**（或实现该建议的框架）

- **我**：
  - **考虑随机性**：应该在分配实验组和对照组时，考虑随机性是否正确，可以查看一些不希望受到测试影响的基线指标，并通过比较这些指标在两组之间的直方图或密度曲线来进行对比，如果没有区别，我们可以得出结论，随机性是正确的
  - **所有指标（包括主要指标和护栏指标）的显著性检验**：主要指标（转化率）和护栏指标（卸载率）都是比率，可以用z检验来检验统计的显著性（python）
  - **最终建议**：
    - **转化率有了显著的增长，卸载率也没有受到负面影响，我建议执行测试**
    - 转化率有了显著的增长，卸载率受到了负面影响，我建议不要执行测试
    - 转化率在统计意义上没有显著的提高，我建议不要执行测试

{{< /details >}}
