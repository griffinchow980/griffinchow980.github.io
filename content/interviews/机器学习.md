---
title: "机器学习"
date: 2024-12-20
---
# 机器学习基础

{{< details "**什么是机器学习？**" "数据分析" >}}

机器学习（Machine Learning）是人工智能的一个分支，通过算法让计算机从数据中学习规律，从而对未知数据进行预测或决策，而无需显式编程。

**核心思想**：

**传统编程 vs 机器学习对比**：

| 对比维度 | 传统编程 | 机器学习 |
|---------|---------|---------|
| **输入** | 规则 + 数据 | 数据 + 结果（标签） |
| **输出** | 结果 | 规则（模型） |
| **规则来源** | 人工定义 | 从数据中学习 |
| **适应性** | 固定规则，难以应对变化 | 自动调整，适应新数据 |
| **复杂问题处理** | 规则难以穷尽 | 可自动发现复杂规律 |
| **典型应用** | 计算器、库存管理 | 图像识别、推荐系统 |

**机器学习的三要素**：

1. **数据（Data）**：学习的原材料
   - 特征（Features）：描述样本的属性
   - 标签（Labels）：监督学习中的目标值

2. **模型（Model）**：学习的算法
   - 决定如何从数据中学习规律
   - 如：线性回归、决策树、神经网络

3. **目标函数（Objective Function）**：优化的目标
   - 损失函数：衡量预测与真实值的差距
   - 优化目标：最小化损失

**机器学习的工作流程**：

```
1. 数据收集
   ↓
2. 数据预处理（清洗、特征工程）
   ↓
3. 选择模型
   ↓
4. 训练模型（学习参数）
   ↓
5. 模型评估
   ↓
6. 模型优化/调参
   ↓
7. 模型部署应用
```

{{< /details >}}

{{< details "**机器学习的三大类问题是什么？**" "数据分析" >}}

机器学习根据任务类型和数据特点，可以分为三大类：监督学习、无监督学习和强化学习。

**1. 监督学习（Supervised Learning）**

特点：
- 训练数据有标签（label）
- 目标是学习从输入到输出的映射

{{< tabs "分类,回归" >}}

**分类（Classification）**

预测离散的类别：

常见任务：
- 垃圾邮件识别（垃圾/正常）
- 用户流失预测（流失/不流失）
- 图像识别（猫/狗/鸟...）

常用算法：
- 逻辑回归
- 决策树
- 随机森林
- 支持向量机（SVM）
- 神经网络

评估指标：
- 准确率（Accuracy）
- 精确率（Precision）
- 召回率（Recall）
- F1-Score
- AUC-ROC

|||

**回归（Regression）**

预测连续的数值：

常见任务：
- 房价预测
- 销售额预测
- 用户LTV预测

常用算法：
- 线性回归
- 多项式回归
- 岭回归/Lasso回归
- 决策树回归
- 神经网络

评估指标：
- MSE（均方误差）
- RMSE（均方根误差）
- MAE（平均绝对误差）
- R²（决定系数）

{{< /tabs >}}

**2. 无监督学习（Unsupervised Learning）**

特点：
- 训练数据没有标签
- 目标是发现数据的内在结构和模式

常见任务：
- **聚类（Clustering）**：将相似样本分组
  - 用户分群（RFM）
  - 商品分类
  - 异常检测
  
- **降维（Dimensionality Reduction）**：减少特征数量
  - 数据可视化
  - 特征提取
  - 去噪

常用算法：
- K-Means聚类
- 层次聚类
- DBSCAN
- PCA（主成分分析）
- t-SNE

**3. 强化学习（Reinforcement Learning）**

特点：
- 智能体（Agent）与环境交互
- 通过奖励反馈学习最优策略
- 目标是最大化长期累积奖励

常见应用：
- 游戏AI（AlphaGo）
- 机器人控制
- 推荐系统
- 自动驾驶

常用算法：
- Q-Learning
- Deep Q-Network（DQN）
- Policy Gradient
- Actor-Critic

{{< admonition type="tip" title="如何选择学习类型" collapse="false" >}}

**有标签数据** → 监督学习
- 分类：离散目标（类别）
- 回归：连续目标（数值）

**无标签数据** → 无监督学习
- 聚类：分组相似样本
- 降维：简化数据结构

**需要序列决策** → 强化学习

**实际项目中**：
- 数据分析岗位主要用监督学习和无监督学习
- 强化学习在推荐系统、游戏等特定领域应用

{{< /admonition >}}

{{< /details >}}

# 常用算法

{{< details "**K-Means聚类是什么？原理和应用场景？**" "聚类算法" >}}

K-Means是最常用的聚类算法，通过迭代优化将数据分为K个簇，使簇内样本相似度高、簇间相似度低。

**算法原理**：

{{< tabs "基本流程,数学原理,优缺点" >}}

**基本流程**

1. **初始化**：随机选择K个样本作为初始聚类中心

2. **分配**：计算每个样本到K个中心的距离，分配到最近的簇

3. **更新**：重新计算每个簇的中心（簇内样本的均值）

4. **迭代**：重复步骤2-3，直到中心不再变化或达到最大迭代次数

示例（K=2）：
```
初始化：随机选2个中心点
迭代1：
  - 分配：每个点归属最近的中心
  - 更新：重新计算2个簇的中心
迭代2：
  - 分配：重新分配
  - 更新：重新计算中心
...
收敛：中心不再移动
```

|||

**数学原理**

目标函数（最小化簇内平方和）：

$$
J = \sum_{i=1}^{K} \sum_{x \in C_i} ,,x - \mu_i,,^2
$$

其中：
- $K$：簇的数量
- $C_i$：第i个簇
- $μ_i$：第i个簇的中心
- $||x - μ_i||$：样本x到中心的欧氏距离

距离计算（欧氏距离）：

$$
d(x, y) = \sqrt{\sum_{i=1}^{n}(x_i - y_i)^2}
$$

|||

**优缺点分析**

**优点**：
- 简单易实现
- 计算效率高
- 适合大数据集
- 效果通常不错

**缺点**：
- 需要预先指定K值
- 对初始中心敏感（可能陷入局部最优）
- 只能发现球形簇（圆形/椭圆形）
- 对异常值敏感

**改进方法**：
- K-Means++：改进初始化方法
- Mini-Batch K-Means：适合超大数据集
- 多次运行取最优结果

{{< /tabs >}}

**如何确定K值**：

1. **肘部法则（Elbow Method）**：
   - 绘制K与簇内平方和（SSE）的关系曲线
   - 找到曲线的"肘部"（拐点）
   - 拐点对应的K值较合理

2. **轮廓系数（Silhouette Score）**：
   - 衡量样本与所属簇的相似度
   - 取值-1到1，越接近1越好
   - 选择轮廓系数最高的K值

3. **业务经验**：
   - 根据业务需求决定分几类
   - 如：用户分群可能分为3-5类

**实际应用场景**：

**用户分群**：
```python
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

# 用户RFM数据
rfm = df[['recency', 'frequency', 'monetary']]

# 标准化
scaler = StandardScaler()
rfm_scaled = scaler.fit_transform(rfm)

# K-Means聚类
kmeans = KMeans(n_clusters=4, random_state=42)
df['cluster'] = kmeans.fit_predict(rfm_scaled)

# 分析每个簇的特征
df.groupby('cluster')[['recency', 'frequency', 'monetary']].mean()
```

**商品分类**：
- 基于商品属性（价格、销量、评分等）聚类
- 发现相似商品群组
- 用于推荐、定价策略

**异常检测**：
- 正常样本聚为一类
- 远离所有簇中心的样本可能是异常值

{{< admonition type="warning" title="K-Means使用注意事项" collapse="false" >}}

1. **数据标准化**：
   - K-Means基于距离，不同量纲的特征会影响结果
   - 使用前必须标准化（StandardScaler）

2. **处理异常值**：
   - K-Means对异常值敏感
   - 建议先处理明显的异常值

3. **特征选择**：
   - 选择对分群有意义的特征
   - 去除冗余特征

4. **结果解释**：
   - 聚类结果需要结合业务解释
   - 分析每个簇的特征统计

{{< /admonition >}}

{{< /details >}}

{{< details "**决策树是什么？有什么作用和原理？**" "数据分析" >}}

决策树是一种基于树形结构进行决策的监督学习算法，通过一系列if-then规则对数据进行分类或回归。

**决策树的直观理解**：

就像一个连续提问的流程图：

```
           [年龄 < 30?]
          /            \
        是              否
        /                \
  [收入 < 5万?]      [资产 > 100万?]
    /      \           /        \
  拒绝    通过       拒绝      通过
```

**决策树的组成**：

- **根节点**：最顶层的节点，包含所有样本
- **内部节点**：代表一个特征的判断
- **叶节点**：最终的决策结果（分类/数值）
- **分支**：决策的路径

**算法原理**：

{{< tabs "分裂标准,构建过程,剪枝" >}}

**分裂标准**

如何选择最优的分裂特征和分裂点？

**分类树常用指标**：

1. **信息增益（Information Gain）** - ID3算法

$$
IG(D, A) = Entropy(D) - \sum_{v} \frac{,D_v,}{,D,} Entropy(D_v)
$$

- 选择信息增益最大的特征
- 偏向取值多的特征

2. **信息增益率（Gain Ratio）** - C4.5算法
   - 改进信息增益的偏向问题

3. **基尼系数（Gini Index）** - CART算法

$$
Gini(D) = 1 - \sum_{k=1}^{K} p_k^2
$$

- 选择基尼系数下降最多的特征
- 计算速度快

**回归树常用指标**：

平方误差（MSE）：选择MSE下降最多的分裂点

|||

**构建过程**

递归构建决策树：

```
function BuildTree(数据集D):
    if 停止条件满足:
        return 叶节点
    
    找到最优分裂特征A和分裂点v
    
    创建节点:
        左子树 = BuildTree(D中A≤v的样本)
        右子树 = BuildTree(D中A>v的样本)
    
    return 当前节点
```

**停止条件**：
- 所有样本属于同一类别
- 没有更多特征可用
- 达到最大深度
- 节点样本数低于阈值

|||

**剪枝（Pruning）**

防止过拟合的关键步骤：

**预剪枝（Pre-pruning）**：
- 构建时设置停止条件
- 如：最大深度、最小样本数
- 优点：简单高效
- 缺点：可能欠拟合

**后剪枝（Post-pruning）**：
- 先生成完整树
- 再从下往上剪枝
- 根据验证集性能决定是否剪枝
- 优点：效果更好
- 缺点：计算成本高

{{< /tabs >}}

**决策树的优缺点**：

**优点**：
- 易于理解和解释，可视化直观
- 不需要数据标准化
- 可以处理数值和类别特征
- 可以处理缺失值
- 非参数模型，无需假设数据分布
- 特征重要性可解释

**缺点**：
- 容易过拟合（需要剪枝）
- 对数据敏感，小变化可能导致树结构大变
- 倾向于过拟合训练数据
- 对不平衡数据敏感
- 单棵树性能有限

**应用场景**：

- **信用评分**：判断是否给予贷款
- **医疗诊断**：根据症状诊断疾病
- **客户流失预测**：预测客户是否会流失
- **推荐系统**：根据用户特征推荐商品

**实际代码示例**：

```python
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn import tree
import matplotlib.pyplot as plt

# 准备数据
X = df[['age', 'income', 'balance']]
y = df['churn']

# 划分训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# 训练决策树
clf = DecisionTreeClassifier(
    max_depth=3,  # 最大深度（预剪枝）
    min_samples_split=20,  # 分裂所需最小样本数
    min_samples_leaf=10,  # 叶节点最小样本数
    random_state=42
)
clf.fit(X_train, y_train)

# 预测
y_pred = clf.predict(X_test)

# 可视化决策树
plt.figure(figsize=(12, 8))
tree.plot_tree(clf, feature_names=X.columns, 
               class_names=['Not Churn', 'Churn'],
               filled=True, rounded=True)
plt.show()

# 特征重要性
feature_importance = pd.DataFrame({
    'feature': X.columns,
    'importance': clf.feature_importances_
}).sort_values('importance', ascending=False)
```

{{< admonition type="tip" title="决策树调参建议" collapse="false" >}}

**关键参数**：

1. **max_depth**：树的最大深度
   - 较小：欠拟合风险
   - 较大：过拟合风险
   - 建议：从3-10开始尝试

2. **min_samples_split**：分裂所需最小样本数
   - 增大可防止过拟合
   - 建议：10-50

3. **min_samples_leaf**：叶节点最小样本数
   - 增大可防止过拟合
   - 建议：5-20

4. **max_features**：寻找最优分裂时考虑的最大特征数
   - 增加随机性，防止过拟合
   - 建议：'sqrt'或'log2'

{{< /admonition >}}

{{< /details >}}

{{< details "**什么是过拟合和欠拟合？如何解决？**" "数据分析" >}}

过拟合和欠拟合是机器学习模型性能的两个极端状态，需要找到平衡点。

**欠拟合（Underfitting）**：

定义：模型过于简单，无法捕捉数据的规律

表现：
- 训练集误差高
- 测试集误差高
- 训练集和测试集误差接近

原因：
- 模型太简单（如用线性模型拟合非线性数据）
- 特征太少，信息不足
- 正则化过度

解决方法：
- 使用更复杂的模型
- 增加特征
- 减小正则化强度
- 增加训练时间

**过拟合（Overfitting）**：

定义：模型过于复杂，学习了数据的噪声而不是真实规律

表现：
- 训练集误差很低
- 测试集误差高
- 训练集和测试集误差差距大

原因：
- 模型太复杂（参数过多）
- 训练数据太少
- 训练时间过长
- 没有正则化

解决方法：

{{< tabs "数据层面,模型层面,训练层面,集成方法" >}}

**数据层面**

1. **增加训练数据**：
   - 收集更多数据
   - 数据增强（图像翻转、文本同义替换等）

2. **特征选择**：
   - 去除不相关特征
   - 降维（PCA）

3. **数据清洗**：
   - 去除异常值和噪声

|||

**模型层面**

1. **降低模型复杂度**：
   - 减少参数数量
   - 降低多项式次数
   - 减少神经网络层数/节点数

2. **正则化**：
   - L1正则化（Lasso）：稀疏化，特征选择
   - L2正则化（Ridge）：参数平滑化
   - Dropout（神经网络）：随机丢弃节点

3. **决策树剪枝**：
   - 限制max_depth
   - 设置min_samples_split/leaf

|||

**训练层面**

1. **Early Stopping**：
   - 监控验证集误差
   - 验证集误差不再下降时停止训练

2. **交叉验证**：
   - K-Fold交叉验证
   - 更好地评估泛化性能

3. **正则化参数调整**：
   - 增大正则化系数α/λ

|||

**集成方法**

1. **Bagging**：
   - 随机森林
   - 减少方差，防止过拟合

2. **Boosting**：
   - XGBoost、LightGBM
   - 逐步修正错误

{{< /tabs >}}

**如何判断过拟合/欠拟合**：

```
学习曲线分析：

欠拟合：
训练误差 ─────────  高且平
测试误差 ─────────  高且平

良好拟合：
训练误差 ╲        低
测试误差  ─────   低且稳定

过拟合：
训练误差 ╲╲       很低
测试误差  ╱─     较高且不稳定
```

**实际案例**：

```python
from sklearn.model_selection import learning_curve
import numpy as np
import matplotlib.pyplot as plt

# 绘制学习曲线
def plot_learning_curve(model, X, y):
    train_sizes, train_scores, test_scores = learning_curve(
        model, X, y, cv=5,
        train_sizes=np.linspace(0.1, 1.0, 10)
    )
    
    train_mean = np.mean(train_scores, axis=1)
    train_std = np.std(train_scores, axis=1)
    test_mean = np.mean(test_scores, axis=1)
    test_std = np.std(test_scores, axis=1)
    
    plt.figure(figsize=(10, 6))
    plt.plot(train_sizes, train_mean, label='Training score')
    plt.plot(train_sizes, test_mean, label='Validation score')
    plt.fill_between(train_sizes, train_mean - train_std,
                     train_mean + train_std, alpha=0.1)
    plt.fill_between(train_sizes, test_mean - test_std,
                     test_mean + test_std, alpha=0.1)
    plt.xlabel('Training Set Size')
    plt.ylabel('Score')
    plt.legend()
    plt.title('Learning Curve')
    plt.show()

# 使用
plot_learning_curve(model, X_train, y_train)
```

{{< admonition type="note" title="偏差-方差权衡" collapse="false" >}}

**总误差 = 偏差² + 方差 + 不可约误差**

- **偏差（Bias）**：模型的预测值与真实值的差距
  - 高偏差 → 欠拟合
  - 模型太简单

- **方差（Variance）**：模型对训练数据变化的敏感程度
  - 高方差 → 过拟合
  - 模型太复杂

**目标**：在偏差和方差之间找到平衡点

{{< /admonition >}}

{{< /details >}}

{{< details "**什么是硬距离和软距离？（在聚类中）**" "聚类算法" >}}

硬距离和软距离是聚类算法中两种不同的样本分配方式。

**硬聚类（Hard Clustering）/ 硬距离**：

定义：每个样本明确属于某一个簇，非此即彼

特点：
- 样本只属于一个簇
- 簇的归属是确定的（0或1）
- 边界清晰

典型算法：
- K-Means
- 层次聚类
- DBSCAN

示例：
```
样本A：
簇1: 0 (不属于)
簇2: 1 (属于)
簇3: 0 (不属于)
```

**软聚类（Soft Clustering）/ 软距离**：

定义：每个样本以一定概率属于多个簇

特点：
- 样本可以部分属于多个簇
- 簇的归属是概率分布
- 边界模糊

典型算法：
- GMM（高斯混合模型）
- Fuzzy C-Means（模糊C均值）

示例：
```
样本A：
簇1: 0.1 (10%概率属于)
簇2: 0.7 (70%概率属于)
簇3: 0.2 (20%概率属于)

概率和 = 1.0
```

**对比**：

, 维度 , 硬聚类 , 软聚类 ,
,------,--------,--------,
, 归属方式 , 确定（0/1） , 概率（0-1） ,
, 边界 , 清晰 , 模糊 ,
, 计算复杂度 , 较低 , 较高 ,
, 适用场景 , 类别明确 , 类别重叠 ,
, 结果解释 , 简单直观 , 更丰富但复杂 ,

**应用场景选择**：

**硬聚类适用于**：
- 类别界限分明的场景
  - 用户明确分为"高价值"和"低价值"
  - 商品明确分为不同类目
- 需要简单明确的结果
- 计算资源有限

**软聚类适用于**：
- 类别边界模糊的场景
  - 用户可能同时具有多种属性
  - 文档可能涉及多个主题
- 需要了解不确定性
- 后续需要概率信息

**Fuzzy C-Means示例**：

```python
import skfuzzy as fuzz
import numpy as np

# 数据
data = np.array([[1, 2], [1.5, 1.8], [5, 8], [8, 8], [1, 0.6], [9, 11]])

# Fuzzy C-Means聚类
cntr, u, u0, d, jm, p, fpc = fuzz.cluster.cmeans(
    data.T,  # 转置
    c=2,  # 簇数量
    m=2,  # 模糊度参数
    error=0.005,
    maxiter=1000
)

# u 是隶属度矩阵（每行是一个样本，每列是一个簇）
# u[0, :] 第一个样本对各个簇的隶属度
print("样本1的隶属度:", u[:, 0])  # [0.95, 0.05] 表示95%属于簇1，5%属于簇2
```

{{< admonition type="tip" title="硬聚类vs软聚类选择建议" collapse="false" >}}

**数据分析岗位实际应用**：

1. **用户分群（RFM）**：通常用硬聚类（K-Means）
   - 需要明确的用户类别
   - 便于制定运营策略

2. **文本主题分类**：可以用软聚类
   - 文本可能涉及多个主题
   - 需要主题概率分布

3. **商品推荐**：可以结合使用
   - 硬聚类：明确的商品分类
   - 软聚类：用户兴趣的概率分布

**实践建议**：
- 先用硬聚类快速探索
- 如果发现边界模糊问题，再考虑软聚类
- 根据业务需求决定是否需要概率信息

{{< /admonition >}}

{{< /details >}}

# 模型评估

{{< details "**分类模型如何评估？常用指标有哪些？**" "数据分析" >}}

分类模型的评估需要根据业务场景选择合适的指标。

**混淆矩阵（Confusion Matrix）**：

分类评估的基础：

```
                预测
              正例  负例
实际 正例      TP    FN
    负例      FP    TN
```

- **TP（True Positive）**：真阳性，预测为正且实际为正
- **FP（False Positive）**：假阳性，预测为正但实际为负
- **TN（True Negative）**：真阴性，预测为负且实际为负
- **FN（False Negative）**：假阴性，预测为负但实际为正

**常用评估指标**：

{{< tabs "准确率, 精确率&召回率, F1-Score, ROC&AUC" >}}

**准确率（Accuracy）**

定义：预测正确的样本占总样本的比例

$$
Accuracy = \frac{TP + TN}{TP + TN + FP + FN}
$$

优点：简单直观

缺点：
- 类别不平衡时会误导
  - 如：99%负例，1%正例，全预测为负也能达到99%准确率

适用场景：类别平衡的二分类问题

|||

**精确率&召回率**

**精确率（Precision）**：

预测为正例中真正的正例比例

$$
Precision = \frac{TP}{TP + FP}
$$

含义：预测为正的样本中有多少是对的

**召回率（Recall）/ 灵敏度**：

实际正例中被正确预测的比例

$$
Recall = \frac{TP}{TP + FN}
$$

含义：实际正例中有多少被找出来了

**权衡**：
- 提高精确率 → 召回率降低（更保守）
- 提高召回率 → 精确率降低（更激进）

|||

**F1-Score**

精确率和召回率的调和平均数：

$$
F1 = 2 \times \frac{Precision \times Recall}{Precision + Recall}
$$

或更一般的F_β Score：

$$
F_β = (1 + β^2) \times \frac{Precision \times Recall}{β^2 \times Precision + Recall}
$$

- β<1：更重视精确率
- β>1：更重视召回率
- β=1：F1-Score，平衡两者

适用场景：
- 类别不平衡
- 需要平衡精确率和召回率

|||

**ROC曲线&AUC**

**ROC曲线**（Receiver Operating Characteristic）：

横轴：FPR（假阳性率）
纵轴：TPR（真阳性率/召回率）

绘制：改变分类阈值，得到不同的(FPR, TPR)点连成的曲线

**AUC**（Area Under Curve）：

ROC曲线下的面积，取值0-1：
- AUC = 1：完美分类器
- AUC = 0.5：随机猜测
- AUC < 0.5：比随机还差

优点：
- 不受类别不平衡影响
- 衡量模型整体性能
- 易于比较不同模型

{{< /tabs >}}

**如何选择评估指标**：

根据业务场景选择：

**场景1：垃圾邮件识别**

重视：Precision（精确率）

原因：
- 误判正常邮件为垃圾邮件代价高
- 宁可漏掉一些垃圾邮件，也不能误判正常邮件

**场景2：疾病诊断**

重视：Recall（召回率）

原因：
- 漏诊代价极高（可能危及生命）
- 误诊可以通过进一步检查纠正

**场景3：信用评分**

重视：AUC

原因：
- 需要排序能力（对申请人排序）
- 不关心具体阈值
- 整体性能更重要

**场景4：用户流失预测**

重视：F1-Score

原因：
- 需要平衡：既要找到流失用户，又不能骚扰忠诚用户
- 类别可能不平衡

**实际代码示例**：

```python
from sklearn.metrics import (
    confusion_matrix, classification_report,
    roc_auc_score, roc_curve
)
import matplotlib.pyplot as plt

# 混淆矩阵
cm = confusion_matrix(y_test, y_pred)
print("混淆矩阵:\n", cm)

# 分类报告（包含precision, recall, f1-score）
print(classification_report(y_test, y_pred))

# AUC
auc = roc_auc_score(y_test, y_pred_proba)
print(f"AUC: {auc:.3f}")

# ROC曲线
fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label=f'ROC (AUC = {auc:.3f})')
plt.plot([0, 1], [0, 1], 'k--', label='Random')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend()
plt.show()
```

{{< admonition type="warning" title="评估指标使用注意事项" collapse="false" >}}

1. **类别不平衡时**：
   - 不要只看Accuracy
   - 重点关注Precision、Recall、F1、AUC

2. **业务优先**：
   - 根据业务成本选择指标
   - 误判的代价是什么？

3. **综合评估**：
   - 不要只看单一指标
   - 结合多个指标全面评估

4. **交叉验证**：
   - 单次评估可能有偶然性
   - 使用K-Fold交叉验证更可靠

{{< /admonition >}}

{{< /details >}}

